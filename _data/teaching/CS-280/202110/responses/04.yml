raw: []
last_ts_read: '1611813499'
offering:
  id: CS-280-202110
cooked:
- desc: I agree with almost everything about the filter bubble. This being removed
    from seeing both sides of an argument has caused the divide in the world to become
    bigger and bigger. This divide is causing most of the issues within north America.
    So many lies and false hoods being created are easily believed because all people
    see is the same rhetoric being spewed from the mouths of people whom, in my opinion,
    are doing it for their own self interest and playing it off as greater good. The
    one thing I don't agree with is Netflix not having filters. When something is
    purely for entertainment value, not political or factual value, there can easily
    be filters to find a movie that you want to watch.
- desc: "Hey everyone,\n\nFor today\u2019s discussion I wanted to bring up the idea\
    \ of polarization, how it relates to social media, and the ethical questions that\
    \ developers working on social media platforms should ask themselves. Polarization\
    \ is basically the division of people into groups that sharply contrast in terms\
    \ of their beliefs and viewpoints. In the video \u2018Beware Online Filter Bubbles\
    \ \u2019 it was discussed how online companies such as Facebook and Google filter\
    \ what you see based on what their algorithms have decided you should see. Over\
    \ time, these algorithms get an imprint of what you like and only offer you content\
    \ based on what they think you enjoy. The issue with this is it puts you in a\
    \ \u2018social bubble\u2019 where no one has a differing viewpoint and everyone\
    \ thinks the same things as you. This \u2018social bubble\u2019 offers a distorted\
    \ view of reality that can cause polarization, as people never get to see the\
    \ viewpoints of other people who disagree with them. Ethically speaking, this\
    \ can cause a moral dilemma for programmers: Do you offer people only the information\
    \ they want to read, or do you offer them a more well-rounded viewpoint? As well,\
    \ this brings up concerns of mine regarding censorship in media: Is it okay for\
    \ online platforms to offer censorship by omission?"
- desc: In our discussion about the purpose and moral impacts of computing, I was
    struck by how many forms of tool can have positive and negative moral impacts
    on the world depending on how the tool is used. A hammer can be used both to construct
    and destroy things. An internet-connected home security system can enable us to
    monitor the safety of our homes in real time from far away, but also provides
    a gateway through which a sufficiently skilled and resourced malicious hacker
    can invade our privacy. A system used by a government to monitor the activities
    of citizens can be used to protect against and punish criminal behaviour, but
    it may also be used to limit legitimate criticism of government. The ethics of
    the use and misuse of technology have a clear impact on the entire world around
    us, but ethics remains a relatively minor focus of most educational programs,
    something I can't say I'm totally comfortable with.
- desc: 'Beware online filter bubbles

    In this video I thought he made a very good point about algorithms tailored to
    peoples personal preferences especially when its done without their knowledge
    and consent, but I think his concerns are most applicable when it comes to news,
    educational, and informative content. I don''t think it has the same weight when
    discussing platforms like Netflix that are primarily used for entertainment, in
    those cases personalized content suggestions absolutely makes sense and its hard
    to see how there are any significant negative ramifications. If people want content
    from a genre they don''t normally watch they can search for it, it doesn''t need
    to be in there recommendations.


    What obligation do social media platforms have to the greater good?

    In the second video I think his point was far more convoluted. In his comparison
    of online space to physical spaces, he seemed to forget a pretty key element that
    people get to pick where they go. There are advantages to platforms with strict
    community guideline just like there are for structured city centers but there
    are also advantages to free less structured platforms that give people license
    to voice controversial opinions just like there are advantages to parks and free
    open areas. Platforms like the parks he said were so beneficial to communities
    serve an important purpose and opting to convert them all into strict structured
    centers is detrimental to communities. If people don''t like going to parks they
    shouldn''t have to go to parks, but the democratic viewpoint should be that people
    are smart enough to decide where they go for themselves. Ultimately I think the
    analogy is flawed since, as he alluded to in the video, a lot of people don''t
    possess the same social anxieties online as they do in person and although that
    leads to far less common curtesy and all around decency, it does come with advantages
    too.'
- desc: "Beware online filter bubbles\nThe filter bubble exists, on all social media\
    \ apps. Eli Pariser brought fore this topic in front of social media executives\
    \ is good. They are the one that controls how this sorting algorithm works. I\
    \ do agree that the filter bubble blocks the user from access all information.\
    \ However, some people are not comfortable receiving all information. They like\
    \ what they like. And it is the job to collect cookies and other data to create\
    \ your bubble in the online work. The main job of social media platform is to\
    \ get you to stay on it as waste as much time as you can to sell more ads. If\
    \ no filter bubble exists, people might see things that they don\u2019t like and\
    \ log-off, which doesn\u2019t generate as much revenue for the company.\nWhat\
    \ obligation do social media platforms have to the greater good?\nWhen you\u2019\
    re talking about the greater good, it usually means the good for the entire society.\
    \ Which likely not going to happen much on social media platforms as there are\
    \ too many users and the flow of information is too quick for these companies\
    \ to control. They do have an algorithm for individual user experience. Facebook\
    \ does try to promote and raise awareness for social issues; however, those are\
    \ likely to be ignored by the user. You can only get user\u2019s attention by\
    \ affective changing their browsing policy. Most people would say things online\
    \ that they won\u2019t in a physical space, no structure in the social media.\
    \ Users act like social media is a free-speech platform where you saying whatever\
    \ you want. Until recently, when it is affecting an actual physical space, more\
    \ attention was raised to help to ban out the bad part of social media.\n\nAnother\
    \ thing is I like being in a small group so we can discuss some of the issues.\
    \ I can understand better from somebody else\u2019s point of view. Like most would\
    \ see computing as a way to process, retrieve and analyze data. Computing has\
    \ become quite popular in all fields of work because it helps users to more productive.\
    \ Hopefully, we can still do that."
- desc: 'In the breakout room today, our group chatted briefly about whether or not
    computing requires a moral framework to support it. I noted that a lot of professions
    require a membership to a type of self-regulating body, and yet computing as a
    profession doesn''t have this same requirement. There are indeed societies that
    you can join, but there is not really a self-regulating body in the same way that
    there are with other professions. Another student pointed out that in the case
    of other professions, there is often a barrier to entry that is quite high, whereas
    with computing, nearly anyone can do it, certified or not. This increases opportunities,
    diversity, and innovation, however this can also mean that it is more difficult
    to regulate.


    https://www.infoq.com/articles/acm-code-ethics/


    I''ve included this link which outline some changes made to the ACM (Associating
    for Coding Machinery) code of ethics, mainly for the interview with Catherine
    Flick that occurs near the end of the article, where she addresses the topics
    that I mentioned at the beginning of this post. It seems it is a difficult matter
    and we have to rely a lot on regulation, and since regulators often don''t know
    enough about technology to regulate it, we end up with ethical breaches that are
    left without anyone to be held accountable.


    https://www.turing.ac.uk/search/node?keys=ethics


    Apparently the Alan Turing Institute is doing work on ethics in technology and
    I''m very interested to see what kind of research comes out of there. I''ve linked
    their database in case anyone is interested to learn more; there are a lot of
    fascinating resources. When I have some free time I''ll definitely go looking
    through it myself.


    '
- desc: "I think the first video of Eli Pariser is spot on and something I have worried\
    \ about more and more over the last few years. This is also especially relevant\
    \ today when you look at countries like America that seem more polarized than\
    \ ever before. You can have two groups of people cannot even agree on what is\
    \ reality. I think this is largely due to these \u201Cfilter bubbles\u201D helping\
    \ reinforce beliefs people already hold and repel them from beliefs contrary to\
    \ their current ones. When I was a teenager, I naively and smugly thought my older\
    \ family members would be far less informed and far more \u201Cindoctrinated\u201D\
    \ because the internet is such a readily available source of information, but\
    \ now I realize it can easily have the opposite effect. You can see this through\
    \ Facebook, Twitter, Reddit or any other social media platform where there is\
    \ zero accountability for accurately or truthfully reporting events. This is related\
    \ to the previous meetings, as we need a way of moralizing what is and isn't acceptable\
    \ to do with technology.\n\nMy understanding of computing is that it is the creation\
    \ of hardware or software through physical or programming means. However, maybe\
    \ there should be more to it than that, as these last few meetings have continued\
    \ to reinforce the idea that you run into all kinds of ethical issues by just\
    \ creating emerging industries and platforms."
- desc: "Vyomesh\n\nFirst video \u2018filter bubbles\u2019:\n\n\_\n\nOne can understand\
    \ the concept of connection to world with internet. There are majority of all\
    \ platforms can see your activity and suggests the outcome to you. It notices\
    \ the link one clicks or searches on internet. I learned that the filter bubble\
    \ is the unique online stage that represent you by your searches, history and\
    \ your data. It limits you to your world only that is one\u2019s relevance. The\
    \ online platforms do have filter algorithm to hide important, uncomfortable,\
    \ challenging and other views. It should be transparent enough that one can see\
    \ else from the personalization. So, user should have right to decide and explore\
    \ all possible outcomes other than the personalization.\n\n\_\n\n\_\n\nSecond\
    \ video \u2018What obligation do social media platforms have to the greater good?\u2019\
    :\n\n\_\n\nThe speaker compares climate change with change in development of new\
    \ Platforms and new tools. The Social media hazard by misleading viral post of\
    \ Facebook, Instagram and other platforms. Spaces shapes the behaviour of human\
    \ by its tendency to optimize mood. Such as the workplace need formal norms and\
    \ so it variates with the places. So, there should be online spaces that can make\
    \ things easier. I leaned that Physical behaviour interacts with the structure\
    \ of online stage. There should have social trust and social proximity by the\
    \ development of new advance platform. Therefore, creation of digital environment\
    \ that respects human diversity by filling gaps with new online public spaces.\n\
    \n\_\n\n"
- desc: 'Key points that stood out:

    Filter Bubble

    - "A squirrel dying in front of your house may be more relevant to you interests
    right now than people dying in Africa" - Mark Zuckerberg, Facebook

    Zuckerberg knows what most people care about I guess... The fact that this was
    the purpose for making the new feed just shocked me because it sound somewhat
    true for

    most people.

    - Companies like FB & Google algorithm''s functions as to remove the links/data
    that one clicks less on.

    - Internet is programmed in a way where it is showing us what it thinks we want
    to see rather than the one''s we need to see

    - easy to be surrounded by junk news/data because of the internet''s algorithm

    These three points also shocked me. Still seems to be an ongoing problem moset
    people need to know about. Especially as it imposes the possibility of people
    missing

    important news which leads to lack of awareness of the things happening...

    - we don''t seem to have clear rules or boundaries in the internet.

    Seems to me that most social media platforms are programmed in a way that because
    of they have no boundaries, people are able to say what they want unfiltered which

    can eventually lead to a platform filled with junk.


    I like these questions:

    What obligation do social media platforms have to the greater good?

    What do we want platforms to stop doing? & What do we need for the greater good?
    -> what public goods do we want from tech platforms?

    What happens when we think of platforms as spaces? -> behavioral norms exists
    in the internet; Twitter is all about loudness, with no bounderies


    Another problem that brought new insights:

    - silicon valley lacks structure because that was its orgins -> too loose = need
    for order and structure

    -> environment is too focused on coding & programming


    - user friendly vs public friendly

    We need a more public friendly application. An application shouldn''t serve just
    an individual but rather wide variety of different individuals.

    soft negative feedback exist in healthy environments and would promote better
    online spaces if implemented'
- desc: 'The most important thing I learned in this past meeting is the morality of
    computing. Its important because its not something I originally would think is
    important but when presented the idea and its implications its easy to see why
    we need moral computing. When we don''t have a code of computing standards and
    ethics we run the risk of problems like those illustrated in the "beware of online
    filter bubbles" video. Because Facebook did not have any strong moral guideline
    to not censor information of individuals without user consent the problem of "filter
    bubbles" arisen without many people noticing. These filter bubbles create environments
    where things like global events were filtered out (potentially keeping individual
    in the dark of important events) and prevented individuals from experiencing certain
    things (like different opinions or things that are challenging) which robs us
    of information we could have had if we did not have these filter bubbles.


    Moral computing is also a tough issue to "fix". Many questions can arise due to
    the fact that "computing" is so large. There are just so many fields that use
    computing so if we consider something is not moral does it cover all these fields?
    If something is immoral on medial computing is that same thing also immortal on
    social media computing? Additionally, if we did have a moral computing code, how
    do we ensure that everyone follows this code. Everyone comes from different backgrounds
    of computing and it is easy to remain anonymous and post whatever (ensuring it
    would be impossible to ensure everyone follows a code of conduct). Thus, I''m
    not sure how we would start addressing moral computing, even if it is important.'
- desc: 'The most important thing you learned from this past meeting

    Eli Pariser discovered the filter bubble because the online companies like Facebook
    and Google provide information to the users as per their search history and behaviour,
    type of computer and location, and things reached to them only as per their interests
    and search areas. Users have no outside world image means they cannot get information
    that is irrelevant to them, which can be anything.


    The concept from this past meeting that was the most difficult for you to understand

    All of the algorithms make filter bubbles.


    What you would like to know more about

    When the users get the information from the outside country, we as users do not
    have access to some internet sites because of regional issues.


    Something you encountered that is related to the past meeting

    I think the internet is the best place for learning. As over there many structured
    platforms, and anyone can learn a lot from there. Undoubtedly, we have some websites
    that have meaningless content over the tech; still, we cannot ignore the internet.'
- desc: 'With regards to if we need a moral operating system when coding, I think
    it vastly depends on what we are looking at doing. If we are just doing small
    personal projects, like making unit conversions, scripting ASCII characters to
    make an image, or testing ourselves by coding stuff in an assembly language, the
    moral implications of that are very minimal. If we are dealing with group projects,
    or anything that the public would end up interacting with, it becomes a bit more
    important to take into consideration the implications of what is being made or
    what it could be used for.


    For example, in our breakout rooms, we where discussing about how no to very minimal
    moral implications would be involved in making a small personal game in Unity,
    but began discussing the implications if the game had multiplayer along with chat
    functionality. What sort of in-game moderation should we decide to put in place,
    to prevent either harm from player to player, or to monitor/limit people from
    planning illegal events. Should we store chat logs to run review on? If so, would
    we have any obligation to forward this information on to authorities?


    In short, small projects with no external usage, outside of a close friend group,
    don''t really require much thinking morality-wise. Anything dealing with the general
    public, or that others will have an interaction with or on, requires some consideration.

    '
- desc: "From past meeting, I watched 2 videos \u201CBeware online filter bubbles\u201D\
    \ and \u201CWhat obligation do social media platforms have to the greater good?\u201D\
    \ by Eli Pariser. In the video \u201CBeware online filter bubbles\u201D Eli talked\
    \ about how internet keep tracks of our information and how internet is using\
    \ invisible algorithm to personalize how different people get different results\
    \ on internet. Filter bubble is basically an online algorithm/editing that represents\
    \ you by your searches and history. It separates what you have been using/searching\
    \ most and show you those data more often than showing other things. On the other\
    \ video \u201CWhat obligation do social media platforms have to the greater good?\u201D\
    \ Eli talked about shapes and structures and how the behaviors of different platforms\
    \ are unstructured. He also talked about the physical spaces, platforms and how\
    \ they are unstructured. He also talks about three platforms and how they are\
    \ analog online such as; Build environment, programming and Mayoralty. He also\
    \ talked about how online spaces should build their platform following the offline\
    \ space."
- desc: "For the first video about filter bubbles on the web or social media apps,\
    \ I\_ think having filters on the internet and social media platform is a really\
    \ interesting concept and that also shows the endless application of computing.\
    \ Filter bubble allows personalized contents to be shown on a users timeline or\
    \ search result and this is widely adopted by the big companies such as Facebook,\
    \ Instagram, Google and twitter . But the issue I recognized is that having a\
    \ filter bubble on a web platform that doesn't give freedom to modify/ choose\
    \ which filters are enabled eventually makes you intellectually isolated or being\
    \ sheltered from opposing beliefs such as the example Eli gave about always clicking\
    \ on liberals news and getting the conservatives comments canceled out.....\n\n\
    On the second Video about what obligations do social media platforms have to the\
    \ grater good, I believe social media platforms have put in a shift as to\_ fulfilling\
    \ their obligations to contributions to\_ a structured social space by fact checking\
    \ news/posts, censoring posts that are not widely morally accepted, suspending\
    \ of accounts that goes against their rules.\_ But I feel as though these measures\
    \ are not sufficient enough as some posts and contents get deleted even when they\
    \ contain credible information."
- desc: 'Beware of filter bubbles - we should yearn to learn outside our filter bubble,
    not seeing only what is tailored for us but also make research on information
    we don''t get to see often. Internet is good if we can learn about things and
    places we don''t get to see often. As an African, I experience this quite often,
    most people only know as much as their internet and televisions show them. They
    paint their entire image about that place from what they see and they fail to
    make some research for themselves.


    Obligations social media have to the greater good - Spaces shape behaviour; which
    is why we should make our social media platforms structured to promote healthy
    public platforms. Social media platforms can imitate some relations from offline
    spaces. This can be done by promoting equity and create some sense of ownership
    for their users.'
- desc: Through this meeting, I learned the purpose of computing. Computers can greatly
    liberate productivity, and it is much faster and more accurate than humans to
    solve complicated questions by computers. Computers have become an indispensable
    part of all fields of society. In the future, I want to know more about the risk
    of computers.
- desc: I found it interesting how these online environments have sort of evolved
    past their intended purpose. By that, I mean how facebook, twitter, and the like
    are all corporations, and features they implement are profit driven. On the other
    hand, they have become important tools for communication for users, and the moral
    operating system would be more for the user's benefit than necessarily the app's
    or company's benefit.
- desc: 'I agree that the filter bubble could be harmful to society. With more globalization,
    it is important for people to be more open-minded and to be able to see situations
    in various perspectives. Filter bubble creates personalized worlds where people
    are surrounded by their own ideologies and with others who share the same views.
    In a multicultural society like Canada and the US, this can only cause more ignorance,
    hatred, and division among people with different backgrounds, political beliefs,
    and religious beliefs. It also hinders people from learning new things. If you
    are only exposed to familiar things and your interests, you have to actively search
    for new information and resist the urge to only seek your interests.


    Like LinkedIn, social media platforms should build structure and environment for
    peaceful interactions between strangers. Structure is more required online because
    of anonymity and distance. People tend to be more hostile to one another and express
    controversial opinions when there are little to no consequences. Having an online
    community can be beneficial for society but unfortunately, more arguments exist
    online than peaceful discussions. The recent censorship on social media is a step
    in the right direction. Social media have the potential to be more influential
    and powerful tools for everyone with more necessary changes. It is their obligation
    to create better environments.'
- desc: 'In meeting 4 i learnt about the importance of computing. During the breakout
    session we discussed the need of computing and most of us thinks same about it:
    i.e. we use code or compute to create webpages and coding is almost everywhere.
    it has become the pivotal part of our lives. there is a great future in this field.

    from the filter bubble video, it can be concluded that the internet is limiting
    us. we are not able to see the things that we should see, but we are encountering
    with the information that internet thinks we should know; in short it is putting
    filter bubbles, that we don''t need.'
- desc: After watching the bubble filter video i came to understand what exactly happens
    what kind of thing runs in our back. My views on that is yes for sure we are not
    getting all the things which we should get like other people to read, to understand
    and also there is an issue of privacy but if there are certain types of actions
    taken against it, might it could be a advantage for example if google is using
    personal information in a encrypted form and we are searching anything what we
    need the platform knows what exactly the user is looking for so rather than showing
    everything it might directly redirects user to the specific things. So I would
    revise myself by saying the filter bubble is the wrong thing but if is working
    under specific regulations might be it is helpful in future.
- desc: "In our last meeting Dr. Hepting was asking the class about, what is our understanding\
    \ of the purpose of computing. We discussed about this topic in different breakout\
    \ season with our group partners. There was also two video that he wanted us to\
    \ watch and talk about that topic based on those two videos.\nThere was two ted\
    \ talk videos, \u201Cbeware online filter bubble\u201D and \u201CWhat obligation\
    \ do social media platforms have to the greater good?\u201D\nIn the first video\
    \ the speaker was talking about the social media, entertainment source and web\
    \ browsers that\u2019s how they keep track about our interests and based on that,\
    \ show us the recommendations which we are using Facebook, Netflix etc. All of\
    \ this sites are more or less similar. They are using some invisible algorithmic\
    \ editing of the web in order to keep track of our interests, personality or what\
    \ we search the most. They can track multiple individuals\u2019 activity at very\
    \ same time even if we make it very different search results. when we are signing\
    \ in and out, what kind of computer we are on, what kind of brows are you using,\
    \ our location everything they can track. All of these sites personalized the\
    \ Facebook, Netflix, google search recommendation based on those informations.\
    \ That\u2019s why when we just simply search about the word \u2018car\u2019 it\
    \ will bring different car brand in front of you based on what you have searched\
    \ before. The speaker calls this whole thing \u2018filter bubble\u2019. which\
    \ is kind of our own personal unique Universe of information that we live in online.\
    \ Because of this filter we are mostly caged inside it and never try to look outside\
    \ of the filter to find out more information.\nIn the second Video, the speaker\
    \ talks about the social media spaces v/s public space. He was talking about how\
    \ individuals take the opportunity to use their social media platform or express\
    \ any opinion, feelings they have. They way public space have some rules such\
    \ as; the behaviours at the bar is not appropriate at the library and maybe vice\
    \ versa, the same way social media also should have that norm. The online spaces\
    \ that encode the same kinds of Behavioral norms, as we can see behaviour on LinkedIn\
    \ seems pretty good and professional then behaviour in twitter. Because LinkedIn\
    \ reads as a workplace and so people follow workplace Norms. We can even see very\
    \ casual and professional profile pictures in there. But tweeting looks so opposite\
    \ of it. In that platform people talk about sports, arguing about politics, flirting,\
    \ trying to get a job and all kind of mixture at the same place with no walls\
    \ or divisions. This gives us an idea that, when we think about Platforms in terms\
    \ of physical space or social media spaces are almost always structured and they\
    \ have rules."
- desc: 'The first video "beware of online filter bubbles is related to the online
    platforms that shows us the things that what they want to show us but not a actual
    information they show us. usually that information depends upon our previous search
    history and what we clicked at first. we all get surrounded by a information of
    junk food.

    The second video is related to that right know we need a new tool to gather society
    but instead internet is making us all apart by transferring wrong information.
    our society need more social gatherings so we have to make products that are public
    friendly.'
- desc: The speaker tells about the concern of the "Filter Bubbles" on the online
    media, which the user can not control what information they want or not, but the
    information are filtered by the algorithm automatically. What we need in today's
    society on the internet is the public ethics that we can control what information
    we want or not, rather than filtered by the algorithm, we need options for the
    online media, the right to choose.
- desc: "Filter bubble by Eli Pariser\nEli Pariser in his tedtalk talked about the\
    \ most disturbing and concerning thing about today's generation which is the privacy\
    \ of an individual and the uniformity of the web. One documentary which relates\
    \ to this topic is \"The Social Dilemma\". The internet was this diverse thing\
    \ that unified us all, it was something that connected us all, but does seem to\
    \ be the scene. The internet helped us to see everything in the world and it was\
    \ great for democracy, but these days Facebook and Google have been personalizing\
    \ the internet for everyone. At first, it was seen as a good thing but it has\
    \ caused more harm than good. Platforms like Facebook and Google have started\
    \ to personalize the internet for the people. They can only see what they like\
    \ which blinds them to the other side of the coin. The thing about these platforms\
    \ is that it shows stuff that you clicked first. You no longer have control of\
    \ the things that you see. This can be used as a very powerful weapon to change\
    \ governments and brainwash kids. The internet before was like a balanced diet.\
    \ With the salads, you got a piece of cake for dessert but now the internet has\
    \ been providing junk to people which is very unhealthy for them. Before the internet\
    \ the gatekeepers devoid the people to access any information about the state\
    \ or other province, then the internet came and it helped to open the eyes for\
    \ the people. Now it seems that we are being guarded by the algorithmic gatekeepers.\
    \ This was first discovered by an engineer at Netflix. It is dangerous when you\
    \ cannot filter what kind of information you want. You feel that whatever you\
    \ search for is right but what is you is always blinded from the truth and you\
    \ never know the truth, just before an algorithm this is a very serious issue\
    \ for today's generation.\n\nWhat obligation do social media platforms have to\
    \ the greater good?\nIn his ted talk, Eli Pariser talked about how the internet\
    \ is messed up. There is fake news on WhatsApp, bullying on Instagram, and rumors\
    \ on Twitter, and we are the very product created by Facebook. He also talks about\
    \ how companies in silicon valley undervalue structure because all the rules have\
    \ been created by the people who live in the lenient city in the most lenient\
    \ country in the world. It would have been different if it was India or China\
    \ on the other side of the spectrum. People think that having rules cage a person\u2019\
    s thinking but freedom does more harm than the norms do. We require structure\
    \ in order to live a balanced life because when things are too loose people crave\
    \ order and structure. We need products for the betterment of the society itself\
    \ and not an individual. A great example he used in his talk is we cannot act\
    \ like at a bar at the office and vice-versa. It feels that social media is like\
    \ a city, people would rather live in suburbs than live in the mess. We need better\
    \ online public spaces."
- desc: In the second video, a city management is compared to a computer software.
    The built environment of the city is compared to computer code, the city programming
    is compared to computer code, and the Mayoralty of the city is compared to computer
    moderators. Its interesting to make a connection of a computer program running
    as an entire city does. The fact he raises afterwards about no one taking the
    responsibility of what people are actually doing on these platforms is very tricky.
    As it would involve a lot of regulations and monitoring. Ethics and morals does
    not hold same standards in everyone's life and its very challenging to regulate
    it in an online platform but that's all the reason that this issue should be considered
    seriously.
- desc: 'As discussed in the previous forum , the main purpose of Computing in my
    opinion is for the endless process of development of both software and hardware
    application and devices.


    My Question to you Professor Daryl is what is the purpose of computing to you
    ?'
- desc: '"Filter Bubbles"

    The TED talk speaker raised some interesting points throughout the video. As the
    title of the peice suggests, the main topic being internet filtering. This filtering
    comes with a variety of problems, depending on how you look at it. One could argue
    that the internet is a better experience if algorithms are feeding you what you
    like, the things you want to see. However, the obvious problem with things like
    this is that you surround yourself with similar ideologies, likes, or interests;
    and essentially isolate the differences. You only see "agreeable ideas, not challenging
    ideas" ("Filter Bubbles"), one never gets the other perspective, other points
    of view. The other glaring problem is that you do not even have a choice of being
    filtered, google, facebook, bing; it is all just automatic algorithms constantly
    adapting to your internet usage, changing what you see on the internet. Although
    a bit of personalization never hurt anyone, I do think that this is a problem.
    I''d rather not have to resort to outlets such as TOR, to get an unfiltered/untracked
    search. I think to close, I''d like to bring up one more important point the speaker
    made in the video. Back in the times where newspaper was the primary information
    outlet, there was an editor who ultimately decided what the public reads and what
    they do not. The internet was supposed to be like that, but it is not. Algorithms
    now determine what you see and what you do not, "we replaced one gatekeeper with
    another" ("Filter Bubbles").'
- desc: "At the meeting 4, the professor asked us to watch a video by Eli Pariser\
    \ \"Beware online 'filter bubbles''. In this video, Eli Pariser told us a concept\
    \ called \"filter bubbles\". So what is \"filter bubbles\u201C? It's a state of\
    \ intellectual isolation that can result from personalized searches when a website\
    \ algorithm selectively guesses what information a user would like to see based\
    \ on information about the user, such as location, past click-behavior, and search\
    \ history. And let the users become separated from information that disagrees\
    \ with their viewpoints, effectively isolating them in their own cultural or ideological\
    \ bubbles. In my opinion, there are pros and cons to filter bubbles for users.\
    \ The advantage is according to its algorism user can easily find what they are\
    \ interested in\uFF0C improve users ' experience. And use it as a way of connecting\
    \ with those who share similar passions, thus deepening your knowledge of a particular\
    \ interest(it's the way used by most of social media like Facebook, Twitter).\
    \ But the disadvantage is the filter bubble may only allow users to know the information\
    \ which the algorism thinks users want to know. In other words, Now all the information\
    \ you know is filtered by filter bubbles. (i think this why Eli Pariser name it\
    \ filter bubbles). I personally don't like this feeling. It like someone is operating\
    \ you behind, you are like a puppet all I know is what filter bubbles want me\
    \ to know. And what I worry about is if the filter bubbles is totally follow its\
    \ algorism? Whether he will be interfered by human factors ?\uFF08like government\
    \ \uFF09Futhermore, if yes, the filter bubbles will be the government's tool for\
    \ controlling public opinion? This needs us to considered carefully."
- desc: 'Hi all, here''s my thoughts on the Social Media video:


    The problems highlighted in the video are 100% accurate. Social Media is getting
    out of hand even for the very creators at it''s core. It is a really powerful
    tool which when used correctly can have a huge impact in solving many of our global
    and even humanitarian crises. That being said, there''s also the flipside which
    is more of what we''re seeing in our day to day life; social media disrupting
    lives all across the globe.

    The point at which it is right now, it will not be retired anytime soon so the
    least we can do is play our part in not spreading toxicity across the board.'
- desc: 'Eli Pariser in first video explains about "Filter Bubble". He wants people
    to know that webpage adapts according to user usage.

    He also gave an example of his own, in which Facebook removed Conservative links
    posted by his friends, because Eli had been clicking more Liberal links

    than Conservative links. This is all due to invisible algorithmic editing which
    is used by all webpage creators.

    Nowadays , Google uses 57 signals to know your search results. Using this signals,
    they can also know your age, location, PC''s information and which browser you
    are using.

    He also told about incident that happened with his two friends, he asked them
    to type "Egypt" in their Google, the search engine , both got different results.
    Therefore,

    It can be said that information I get is no longer the information you get. He
    also said that this algorithm is providing us steady diet information but we need
    to get balanced diet information which includes

    uncomfortable , challenging , and important.

    At last , he said that Internet should be something that introduces us to new
    ideas , new people and different perspective.


    Eli Pariser in second video explains about "Spaces shapes Behavior". There are
    a lot of problem going in this world like Global Warming, spreading of fake information
    and mass migration.

    This can be solved by bringing people together. Initially , Social media were
    thought to be the platforms that can bring people together. But the result is
    opposite of this. It usually widens gaps

    between people. This is because of spreading of misinformation, nasty talks, fight
    on silly things that too on social media like Facebook, Twitter, many more.

    Designer of social media platform need to take help of social psychologist and
    urban planning. According to social psychologists , the physical spaces can influence
    human through their design.'
- desc: Last meeting we discussed some of the concepts that were in the filter bubble
    video. I found one thing particularly interesting during this discussion, that
    being whether or not code is unbiased or not. When I really think about this I
    can only come up with one conclusion. My thoughts on this are that no code can
    be made to be unbiased because it is made by a person. People by nature have their
    own personal views on any given thing and this whether intentional or not directly
    affects the tasks they do in this case being coding something. That is kind of
    a scary idea especially in the present date and how much programs and the like
    control our world. For instance, the other day I was researching some computer
    components because I had a suspicion that one of mine is starting to wear out.
    Next thing you know I'm seeing advertisements and links related to the parts I
    was searching for, I was directly being targeted and marketed to.
- desc: Actually it was nice experience I had a group and we created a word document
    for writing out our thoughts on the 2 videos which were uploaded. We discussed
    the positives and how can data be used nicely what are future possibilities in
    improvement. How can we make decision making useful and so on. So it was nice
    experience meeting new people and interacting with them
- desc: "For the last meeting, we discussed the student blog description and how the\
    \ internet society developed. Also, I have watched the video Dr. Hepting provided\
    \ for us: \u201CBeware online filter bubbles\u201D and \u201CWhat obligation do\
    \ social media platforms have to the greater good?\u201D Here are my analysis\
    \ of videos:\n\nFor \u201CBeware online filter bubbles'':\nthe most important\
    \ thing you learned from this past meeting:\n\nI\u2019ve learned the internet\
    \ search web will offer results that their filter algorithm gives you that you\
    \ don't really need. It is based on gathering information from the first click\
    \ you made and using one sugar one pain strategy, which gives you one result you\
    \ like, one you don't. So, we need to be aware of what you research and what results\
    \ you get,always pay attention to get useful information.\n\nthe concept from\
    \ this past meeting that was the most difficult for you to understand:\n\nwhy\
    \ google and yahoo and many big internet research companies do not balance the\
    \ user\u2019s need and profit by making a user acceptance testing or if they do,\
    \ why the problem still exists?\n\nwhat you would like to know more about:\n\n\
    I would like to learn more about the filter bubble algorithm alternative version\
    \ to improve the user\u2019s experience.\n\nsomething you encountered that is\
    \ related to the past meeting:\n\nWhen I do google search for questions, sometimes\
    \ I need to view a few pages to get the information I want.\n\nFor \u201CWhat\
    \ obligation do social media platforms have to the greater good?\u201D:\nthe most\
    \ important thing you learned from this past meeting:\n\nWhat cause there are\
    \ some platform is mess, some platform is clean and people are following rules,\
    \ with civilized languages, the answer is environment, so, from the speech, the\
    \ guy told us, the looser rules areas are more mess than strict rule areas, sometime,\
    \ we need to choose the most suitable area for us to stay.\n\nthe concept from\
    \ this past meeting that was the most difficult for you to understand:\n\nHow\
    \ the relationship between city structure tightly connects with platform structure?\n\
    \nwhat you would like to know more about:\n\nHow do we fix the side effects of\
    \ strict rules and loose rules.\n\nsomething you encountered that is related to\
    \ the past meeting:\n\nThere are many bad words on some free chatting platforms\
    \ that make people unhappy, and some study platforms are very structured and organized."
- desc: we discussed our understanding of the purpose of computing in small groups
    where we had to share our thoughts and get to know one another. Apart from this,
    we were asked to watch the video about filter bubbles. Definitely want to learn
    more about filter bubbles in the next class.
- desc: Online filter bubbles is a really relevant question in nowadays. It explains
    how algorithms feed different information to different people. It shows what the
    internet thinks what we need to see rather than what we should see. It limited
    people interact with people that have a different idea with them. It is one of
    the reasons that people's idea becomes more radical because people are being fed
    with the same information over and over again. This creates misunderstanding and
    untrust between different people since they can learn different information but
    does not know people are the other side feel.
- desc: 'WOW! That was my reaction after watching the filter bubble video. We really
    really need to keep an eye out for the invisible news feed, about how the tech
    companies are showing us what THEY think is relevant to us. The tech giants are
    literally dominating what we see, how much we see and they are narrowing down
    our thoughts. Isn''t it scary that these companies control our thoughts and emotions
    by showing us what they want us to see? What I deduce from the Filter bubble video
    is that we should have control of what enters and exits our own internet bubble.


    Social media can be both a great handy tool as well as a lethal weapon destructive
    enough to take lives. From the second video, I learned that what social media
    is lacking is a civic responsibility. Today they don''t even justify their own
    name "social" media, it was supposed to link people together, it is supposed to
    be a platform for people to come together rather it has become a platform to make
    riches. Monetizing social media is a huge mess. From what I learned, I believe
    that for now, we should leave the online platforms a place to visit rather than
    make it a home which most of us are really doing right now.'
- desc: "I had added my response to Filter Bubble videos on Meeting 3 forum. So I\
    \ will just repeat that response here:\n\nThe most important thing that I learned\
    \ was that the few big tech players have a lot of control over how people experience\
    \ the internet. Although it may be unintentional, but the design decisions of\
    \ these big tech players, as well as their drive to generate increasing profits\
    \ has put the people\u2019s natural shaping of opinions and attitudes at stake.\n\
    I would like to know more about how the filter bubbles and other similar phenomenon\
    \ are impacting our lives. Additionally, how is technology playing a role in spreading\
    \ misinformation and falsehoods, and how technology itself can be used counter\
    \ that."
- desc: I think we can do more group discussion in the class, which help us understand
    the course and others.
- desc: "In these two videos, the first video was about filter bubbles. It is kind\
    \ of a condition in which a online user only sees the information of their interests\
    \ instead of all kind of information that we need to see. This situation is caused\
    \ by invisible algorithms, who are editing the web. It\u2019s like creating a\
    \ personal unique list of our interest. For example, as eli pariser said, if two\
    \ persons are searching for same thing in their individual browsers they are more\
    \ likely to get different search results and that is because these digitals algorithms\
    \ shows results on the basis of our search history, location and all others things\
    \ that we search more often. But this is causing worldwide problems of imbalance\
    \ information delivery. As we should see the things , arguments , news of our\
    \ opponent\u2019s view and with whom we may not agree. This is necessary for keeping\
    \ ourselves updated on every condition that we are likely to face in future. And\
    \ it also shows the lack of ethics in digital web editors .\nSecond video was\
    \ about TED platform, which means online spaces where worldwide people meet to\
    \ share their lively information, views and Work related topics For example, twitter,\
    \ facebook and linkdien. And the discussion in the video was about the problems\
    \ with these platforms. Like the online unstructured public spaces which shows\
    \ the lack of ethics, manners and social behaviour. To make it more clear, we\
    \ can take the example of Twitter, which has no rules about the public behavior,\
    \ no walls , no diversion and the kind of information that public should expose\
    \ to. Instaed of a informational tool these apps are more than like pubs and fun.\
    \ On other hand , linkdin like apps have proper structure , rules and purpose\
    \ for what people will make link with each other. Here public behaves like professionals\
    \ and that is quite good to see and learn for everyone. But other apps are like\
    \ massive public gatherings discussing the best or wrost topics with no order\
    \ or structure. Today, This is worth to consider that these ted platforms are\
    \ obligent towards us to create a neat and ordered online public space in exchange\
    \ of the power that we allow them to hold. Why not online spaces be as organized\
    \ as physical spaces. Digital designer needs to think on the environment that\
    \ respects the diversity of human existence. There is need of digital urban planets,\
    \ good digital architecture and trans national movements. At the end, i think\
    \ this topic is urgently worth considered to solve."
- desc: 'from the posted two videos, one video was about the filter bubbles. which
    is algorithms that run and control the provided service. it is more likely to
    say that these are web editors, which edit the information provided to every specific
    online user. for example, as discussed in the video, two individuals can have
    different search results for the same search topic. and i completely agree with
    eli pariser''s concern about the the type of information that we are exposed to
    , nowadys, beacuse it is not worth using the technology for the thing that only
    interests us. instead we should be also seeing other''s point of views. as that''s
    what internet is for, to connect different diversities, different thoughts.

    secondly, other video was about the disordered and unstructured online platforms
    such as, facebook, twitter, instagram and a lot of ther social apps. it was suggested
    on the video that we can have more ethical and neat public places on these apps
    but that is only possible if some rules will be designed to behave themeselves
    for every online user. and this can only be done if digital designers give it
    a thought to make such apps a good informational and learning tools with ethical
    users.'
- desc: 'well from there are two videos that was about the filter bubbles from which
    we get that the online user only sees that the information of their interests
    from that the means of all kind of information that we need to see and we can
    say that the algorithms who are they editing the web. its like creating a unique
    list of our interest. and in their individual browsers they are more likely to
    get different search results and it is because that the these digitals algorithms
    show results on the basis of our search history , location and all the other things
    that we search more often.as we should the see the things and arguments and with
    whom they are not agree. and it also shows the lack of ethics in digital error
    webpage.

    and the discussion in the video was about the problems with these platforms. and
    the second video was about the ted platform which means online spaces where worldwide
    where people meet to share their lively information views and work related topics.

    for example twitter , facebook and linkdin.'
- desc: 'https://www.freecodecamp.org/news/developer-ethics/.


    With all this talk of ethics and morality within programming I thought I would
    share an interesting link that links to multiple cases of ethical approaches to
    coding and cases of unethical behaviour in programming.'
- desc: "1. the most important thing you learned from this past meeting\n- what is\
    \ potential of computer science, in next few years\n- important for everyone to\
    \ learn coding\n- profit vs ethics\n2. the concept from this past meeting that\
    \ was the most difficult for you to understand\nhow can we choose between ethics\
    \ and profit, in a particular situation what we can do, should we hinder someone\u2019\
    s privacy to make profit or not\n3. what you would like to know more about\nunderstanding\
    \ moral operating system in detail, and how can we use technology so it does not\
    \ empower us.\n4. something you encountered that is related to the past meeting\n\
    - we can see privacy of user, is questionable nowadays, every thing you speak,\
    \ take photos, search the data is recorded and used against us to influence us.\n\
    - I came across a great video where google uses audio to know what you want to\
    \ buy\n- Link: https://youtu.be/zBnDWSvaQ1I"
- desc: Well from what i learn about in class by discussion with my other classmates
    is that this that we should have these tools because its better then not having
    them but we still need the eithics system to make sure nothing bad happen.
- desc: The point is filter bubble is an online climate where individuals are presented
    to impart their insights and data that adjust to their current convictions. for
    the most part, it structures when algorithms used to curate the substance data
    created by clients via online media dependent on their perspectives and viewpoints.
    Google recommended that personalization improves the experience of clients however
    an excessive amount of personalization can make filter bubbles. what's more, it
    is unsafe for people groups and society. what happened when we search something
    on the web when a site algorithms specifically guesses what data clients might
    want to see dependent on data about the client, similar to the area and search
    history and so on accordingly, clients become isolated from data that can't help
    contradicting their perspectives. the decisions made by these algorithms are not
    straightforward. algorithms don't clarify everything. it is an issue of human
    instinct. it turned into a human weakness on the grounds that we don't need our
    plans to be tested. so it is a one sort of issue to us.
- desc: 'In the filter bubble TED talk the guy talks about Facebook and google filtering
    our search results and news feed based on all kinds of different personal data
    so they can show us stuff that most relates to the individual user. As mentioned
    in the video this creates a problem since users don''t get to see all of the information,
    all the information displayed is specially selected for each user but there is
    so much that users don''t see that might be important. This is especially prevalent
    today with the big social media companies gatekeeping information from users that
    algorithms and moderators do not agree with, creating a one sided information
    source. Information sources should be displaying everything(within reason of course)
    and not have any kind of bias.

    '
- desc: "Eli Pariser begins his talk with the variety of the links provided by the\
    \ Search engines such as google, Yahoo etc. to the users. He begins his talk with\
    \ the example of his friends that how the variation can be seen by searching the\
    \ same topic. Later, he focusses on the concept of the \u2018Filter Bubble\u2019\
    . He focused on how the search engines detects the activity by sharing his own\
    \ example with the Facebook.\nIn his second video, he talks about internet and\
    \ how it makes away from each other. The world of Internet is big, but we need\
    \ to get together more often. Morals does not hold same principles in our life\
    \ these days and its difficult to manage it on this big level and same goes with\
    \ ethics"
- desc: 'The most important thing I learned from the past meeting is the way in which
    online platform works and shows different results to same thing searched online.
    The results which is shown to us are directed by different AI machines and sometimes,
    this filters removes the important stuffs we should know about.

    The other thing which is also a topic to be looked at is the way in which online
    platforms are structured. The software developers should thing of the ethical
    norms which must guide the way in which the softwares must works. It should create
    a healthy environment for people entering the public platform so that they can
    connect with each other easily and be able to motivate themselves to be a better
    human being. It''s a high time, and we need better online public spaces and digital
    urban planners so that people can build trust among themselves and humanity can
    grow.'
- desc: In our fourth meeting we discussed in our own student groups how much power
    and control (or lack thereof) over people's opinions and personal data and what
    should be done for it. A big idea in place was to put a moral structure of some
    kind for all social media company ethos to derive from.
- desc: 'In the first video beware of filter bubbles, revolves around the issue with
    how tech companies gradually personify what each individual sees on their feed
    according to their interest based on what they watch or click on the internet.
    Although making people see what they are really interested in isn''t really a
    bad idea it blocks out the other information they could be knowing especially
    when the information is filtered without these individuals even knowing. the video
    throws light in this and suggest that tech companies should allow people see not
    just what interests them but a little bit of everything therefore giving them
    a balanced diet of information.

    The second video is more about how social media is really crowded with all sorts
    of different people in one place. The video suggests a call to the need of structure
    on social media so as to make it a safer places and allows for better interactions
    with different kinds of people.'
- desc: "\u201CBeware of online filter bubbles\u201D: This clip shares about how is\
    \ Internet working in the modern world at the moment. Nowadays, lots of people\
    \ use Internet everyday and every time. For that reason, Internet becomes the\
    \ valuable resources for many people who working in this field. Many platforms\
    \ such as Facebook, Google, Yahoo, Amazon start to collect users\u2019 personal\
    \ information in order to improve their systems as well as personalize the platform\
    \ for users. This could be convenience since people can easily enjoy things that\
    \ related to their interests while they are using Internet. However, users should\
    \ be aware of those social platforms. Users could not know which their own information\
    \ be collected. Moreover, their information could also be sold by them for other\
    \ platforms so that other platforms can use them to advertise. In general, everything\
    \ has two sides. Internet users should be beware of the social media/social platforms\
    \ while using them.\n\u201CWhat obligation do social media platforms have to the\
    \ greater good?\u201D: This clip delivers the content that social media platforms\
    \ are just similar with the houses that we are living in. For that reason, while\
    \ using them, we should keep them as clean as our houses. Each platform has its\
    \ own norm so that users should adjust themselves in order to be suitable for\
    \ each platform. For instance, LinkedIn has a norm of workspace so that on LinkedIn,\
    \ user usually post things that related to working. Moreover, they also set their\
    \ avatar in the way that similar to them when they are going to work in the real\
    \ life. In other hand, each platform also needs to define which characteristic\
    \ that it wants to be so that the platform could build their web, their page suitably.\
    \ In conclusion, that is the only way helped social media platforms become better,\
    \ more reliable and also more professional."
- desc: In the past meeting, the concept of filter bubles highlights some issue regarding
    searching information .Different people gets different result when they search
    the same thing. There are some algorithms that act as a gatekeepers that control
    the flow of information. People only get relevant information but not that information
    that let them know the other points of view. Filter bubble has created a state
    of isolation from information that diagrees with their viewpoints.It has created
    a sense of not knowing the good piece of information. The algorithms must embedded
    some ethics that could have a sense of the public life and a sense of civic responsibility.
    This will help people in growing up good relationships with others and creating
    a healthy environment around .
- desc: 'In the video filter bubble, the speaker inclines more towards personalization
    of the web. He focusses on how the internet takes our input as the information
    and show the feed what they think is right for us. I feel, the approach they take
    is more psychological rather than technological.

    He also reflects on a filter bubble which is covered with various web application
    including facebook, google, netflix, etc.. and how it works to attract our attention
    and gain more engagement. Additionally, he also we are covered with filter bubble.
    They consider us as their products rather than customers. He also compares the
    Internet news with the newspaper in the early 19th century. He emphasizes how
    the newspapers were crucial and quite filtered at that time to be self aware of
    the ambiance and major events the world. He request the web organizations to encode
    such algorithm which might affect people''s sentiments and emotions.


    In another video, he reflects on space. The context of a shape is important. Every
    context gives an opportunity to imbibe a lot of norms and shapes our behavior.
    Metaphorically, the speaker compares physical space to online space. I feel, it
    has vast difference between them and shape our behavior in different way. Online
    media need to encourage meaningful public dialogue to help people address the
    pressing issues of our time.

    Global warming, false news, mass migration-these are challenges that people can
    only solve by working together.

    Yet the burgeoning sites of social media that promised to bring people closer
    together have become lawless spaces full of disinformation and unpleasant talk.
    Therefore, the online space should be public-friendly rather than user-friendly.'
- desc: 'Filter Bubble

    In this Ted talk Eli Pariser describe how internet is changing not in a good but
    in a bad way. All big companies uses our search history and saw us the thing which
    they like. In other way we are just watching what we like but internet is social
    platform where everyone goes to watch something new, we don''t just want to see
    what we like, users what to see everything flouting around them. If the new search
    is showing the thing based on old search or if we browse something on any social
    media and getting the result of what just we like then how we are connecting with
    the world, it is like that we have created our on personal space on internet like
    group of few friends, in a technical way we are trapped in the loop called filter
    bubble. Another disappointing fact is that this companies are using our personal
    information like which computer we are using, location the way this algorithm
    work is not ethical.


    What obligation do social media platforms have to the greater good?

    Eli Pariser in his ted talk talk describe about the importance of public friendly
    platform rather then user friendly. He talk about the fake news and rumour which
    people forward on what''s app, messenger which is not right, according to me,
    we as a user should not do that. Many people consider that as a real news. Social
    media should not have any cover over it, it should be transparent as much ass
    possible. their should be different space for every work.'
- desc: 'My understanding of the video filter bubble and what obligation do social
    media platforms have to the greater good.


    Filter Bubbles: The video talks about how as individuals, if multiple users use
    google to search for the same piece of information they tend to get different
    results and this algorithm is called a filter bubble. This occurs due to the fact
    that the internet shows us what it thinks we want to see and not necessarily what
    we want to see. In conclusion, users should be able to control on what gets taken
    out and what''s included in the result of their searches.


    what obligation do social media platforms have to the greater good: This video
    enlightens us on how social media isn''t necessarily a safe space because it sets
    us against each other e.g. Bullying on Instagram and facebook. What we need is
    for online digital spaces to be our new home where we are comfortable about posting
    things, where we have some ownership of what we post and lastly a safe place where
    our kids should be able to use and not be scared of cyber bullies, phishing and
    also accidentally downloading malware.'
- desc: 'After watching the video "Beware online filter bubbles", I am very surprised
    that the information returned to me is not the same as the results that other
    people seeing, even we are searching for the exact same topic, just because we
    are in different cities and we are using different computers. It is so unbelievable
    that the information has been personailzed by algorithms based on our daily behaviours.
    What''s worse, those results may not be what we need to know. Instead, this is
    the information that machines and algorithms want us to see. And the filter bubbles
    are controlling people and making us live in our unique universals. With filter
    bubbles engaged through the Internet, we have lost right and power to decide what
    we should know. To prevent the situation from getting worse, these popular search
    engines and applications such as Netflix and Google should stop relying on ruthless
    algorithms, but rather artificially censor information. Another solution by using
    algrithms for filtering information purposes is to allow users to choose what
    they want to see. However, in my opinion, the second choice is too hard to come
    true.

    For the second video "What obligation do social media platforms have to the greater
    good?", I have learned that each platform online can be treated as a space. Like
    a good physical space, any good online platforms should maintain a good structure
    as well, which means the platform has to setup rules for users to obey and follow.
    Humans are highly creative and sensitive intelligent organisms. In order to protect
    human beings from their own harm, we have always obeyed various laws to regulate
    our behaviours. Therefore, it is the responsibility of every online platform to
    lay down regulations for their users. However, most of platform are focusing on
    how to make the product more user friendly, ignoring how to make public friendly.'
- desc: "From the video we learned about how the search results depends on many various\
    \ features and how different it can be from one another. We also learned about\
    \ filter bubble which let us be in our own world and shows the results depending\
    \ on your history or what browser you use and many other things. And the main\
    \ point here is we don\u2019t make the choice of what we want to see, they make\
    \ the decision for us. So as a society we need to tell people to look at this\
    \ point and show the results irrelevant to what place or browser you are using.\n\
    \nSpaces made behaviour and kind of environment"
- desc: 'In this meeting, we were split off into groups and told to discuss about
    the various things. The group I was in, ended up talking about how there is a
    bias in the way the current systems are set up and how this bias will propagate
    into any system or any ''moral'' system that we design if we let it go unchecked.
    There is need to talk about this and put more effort into creating new sets of
    data which overcome this bias and have a fair representation for everything.

    '
- desc: 'My observation for the Beware online filter bubbles video is social media
    has to be motorized and sized by the arithmetic filters which can be dangerous
    because it depends at certain orders or like a first click to collect our data.

    For the second part, the summary can be the obligations do social media platforms
    the organized structure of our cyberspace. Social media become the new way we
    spend our time with. Thus, Taking design cues from scientists, technologist shows
    how the problems we are encountering on digital platforms are not all that new,
    and how, the model of thriving towns and cities can create trustworthy online
    communities.'
- desc: When we using the social media apps, whether facebook or twitter or Google
    etc. All of these companies recommend something to us, sometimes even the advertisements.
    In fact, there are based on the algorithms so we might see different pages depends
    on our location or searching history. It is not always a good thing because since
    we are see different things, it could have something like media bias, and people
    cannot judge things properly. So that instead of stuck in the information that
    these companies provide to us, we should have seen more than it.
- desc: "I never imagined how social spaces have such great effects on the society.\
    \ In the video it sure seems like some websites are messing with the web results\
    \ or preferences but I can only think that it is a debatable topic. Who wouldn\u2019\
    t want to have their options based on their preferences? But at the same time\
    \ people do thrive for knowledge beyond their preferences. In contrast to Daniel\u2019\
    s and Scott\u2019s search results, what if Daniel had a family in Egypt but the\
    \ google results didn\u2019t show any news article but only tourism results. He\
    \ would have missed out on the information. Internet trying to bound my thinking\
    \ sure makes me uneasy. Social media websites should be more responsible for what\
    \ their algorithm does. It might be difficult to add ethics to those problems\
    \ but they need to overcome that."
- desc: In "Beware online filter bubbles" i learnt about personalization, the speaker
    said personalization is the internet showing what we want to see not what we need
    to see, different people get different things, he said a lot of companies are
    doing this now, I also learnt about filter bubbles , this is your own unique information
    that you live online, depends on who you are and what you do, you don't decide
    what gets in or out of your filter bubble. we need companies to allow our filter
    bubble to have a sense of public live so we can have a sense of belonging and
    they should also be transparent.
- desc: "So for meeting 4 we discussed a bit about what the class will be with assignments\
    \ projects and final exam, then we started to discuss the videos for meeting four\
    \ on filter bubbles and how social media platforms have an obligation to the greater\
    \ good.\_ while discussing these videos we split off into groups and in are group\
    \ we discussed how with filterer bubbles that when it comes to important discussions\
    \ like politics there shouldn't be a filter that only shows what the person likes\
    \ it should show all sides of the topic and then let the user make there decision\
    \ on what they believe is right.\_ in this video it brought up apps like Netflix\
    \ in there examples and we believed that this was wrong, for apps like Netflix\
    \ filter bubbles are perfect its helping you by showing movies or shows like the\
    \ ones you watched before.\_ when it comes to personal entertainment filter bubbles\
    \ are perfect for apps.\_\n\n"
- desc: After watching the filter bubble video, it brought to my attention to what
    I believe is a crucial problem. Limited access to information based on our filter
    bubble can greatly hinder the information we have that influences our opinions.
    I've noticed this with people in my family forming opinions on the virus, politics,
    etc. A lot of people are influenced very easily by what they see on the internet
    and they rarely go out of their way to research beyond what first pops up for
    them in a google search. Another factor of this information problem is that most
    people are not aware of these filter bubbles and assumes a google search result
    would be the same for everyone. After looking further into this feature, I have
    found that if you go to https://adssettings.google.com while logged into a google
    account, you can actually see every assumption google has made about you and the
    information they are using to generate your filter bubble. It is quite interesting
    to check out.
- desc: 'filter bubbles


    In the video filter bubble, the host Eli Pariser talks about how the so-called
    free internet is being manipulated by filter bubbles. All the information we see,
    depending on various criteria and user data, can be very different from person
    to person. Now, as he said in the video, according to Google CEO, learning about
    a backyard squirrel can be more relevant to us than seeing people dying. Now,
    that is true in a sense. We do get numb by repeating news no matter how horrifying
    it is. So what we are getting is a balanced diet, a bit of cute fluffy puppies
    with a bit of war and death. but are we? as the host showed that his friends got
    different results for the same search result. But then again, this video is a
    decade old and the "algorithm" and search preferences have changed in the last
    10 years. But has it? I purposefully followed some right-wing pages, mostly run
    by American war veterans and most of my suggestions were anti-BLM protests. So
    I am not truly being a part of the vast internet but rather a part of a small
    bucket cause all I am knowing is about the same ideology and beliefs over and
    over again. And even if there is a moral system that let us know about not only
    what we believe in, but also important, unimportant, different point of view,
    will there be someone who is controlling it or would it be absolutely free as
    news flow should be? Cause if it''s not, as Eli said, it will just be passing
    the torch to someone different.


    What obligation do social media platforms have to the greater good?


    People crave order in a place that feels orderless the most while giving birth
    to authoritarianism. Social sites were born out of California in The U.S. which
    is one of the reasons Eli Pariser thinks it''s so out of the structure. And that
    is feeding the new issues we are facing through social media, instead of connecting
    to people, to understand them, instead, hate and misinformation are spreading
    rampantly. Social media can be called the new cities, new virtual cities. The
    platform seems new, its problem seems new but we have been facing similar issues
    for a quite long time. According to Eli, cities sorted out its problem by making
    structures in the cities. Specific places to live, to shop, for children to play,
    and to go to work. Which is sort of lacking in social media because everything
    and everyone is free to do what they want which creates an environment of "mess".
    Now, when he was talking about the stuff at town hall meetings and going to the
    park for a picnic or a romantic stroll, that reminds me of some of the groups
    that I am in. These groups are very specific on the topic. For example, one is
    about only wholesome stuff, nothing else, another one is about geopolitics. Either
    place, the not nice person gets kicked out and also both places are regulated.
    I love those groups cause I can see kittens and learn a whole lot about today''s
    world while hearing the stories of both sides. But at the same time, they are
    "regulated". Should an open platform really be that regulated? Besides, as Eli
    mentioned, these virtual public spaces are privately owned. We are using it basically
    for free, or by selling our user data to be more precise but we do not hold any
    real control over it. There is no law either apart from what everyone mutually
    hates. So we do need new platforms or heavily reform the existing ones. The question
    is, who? When the entire space, satellites, and orbits are almost lawless, what
    can we do to regulate cyberspace? As a non-American, I will not accept any rules
    passed by an American court while I''m browsing the internet in South Asia. We
    need international cooperation and good-hearted volunteers to make this one possible.
    Who will not consider the internet and social media as a cash cow but rather as
    a new dimension which can be modified to create something artistic and worthful.'
- desc: The videos are same as last week mainly describing the effect of internet
    algorithm in our future lives and how filter bubbles stops us from growing.
- desc: In social media, messages are disarray. As the talker said, the facebook now
    is make him start think of 1917s NewYork.;Messages are everywhere, netizen will
    focus on hot event rather than focus on their interest. Politics, democracy, emotion,
    gender all exposure under the internet. The obligation that social media platforms
    have to do first is filter the messages, a peace world need a peace environment
    to support. Because in 21 center, internet can be entertainment, it also can be
    weapon. Some fake report might effect serious consequence, and netizen are not
    able to determine weather the report is real or not, chain reaction will happen
    then lead the case to worse direction.
- desc: These news sources on the internet are all we have and get, it may be false
    and it may be the correct only way to know is to do more research than the news
    article has given. Politically most news sources favour one side and will try
    and filter out any bad that comes for example fox news. These news sources stay
    relevant because they have a fanbase that fuels them to continue putting out the
    same things. We are given a choice when we first log in and after that everything
    is filtered to what we like reading, these sources make a profit based on how
    long we stay. I would like more control but for that, I have to take action myself
    by widening my search and putting research into things I believe and see.
- desc: "The fourth meeting presented a great opportunity to learn from one another about\
    \ the videos from last lecture. Eli Parsier\u2019s filter bubbles and on the accountability\
    \ of internet organizations were the main topics discussed. The critical hidden\
    \ gem in the meeting were when we presented our ideas in a group based session.\
    \ My team composed of four people, all of which coordinated effectively and efficiently\
    \ to pop into a Google Docs room, and began jotting down discussion points. Each\
    \ of which we discussed and debated for a few moments. The key takeaways from\
    \ that breakout room discussion would be how filter bubbles have a cascading effect\
    \ in society. Driving us further and further into our own realm of the internet,\
    \ and effectively providing a false bubble of reality. Blocking objective and\
    \ constructive discussions and presenting half truths as statements. I believe\
    \ strongly that one should always have a conscious thought while going through\
    \ news articles as no article or piece of information is without inherent bias.\
    \ The defining feature of human problem solving is our ability to digest multiple\
    \ parts of an event and dissect each side\u2019s argument with a logical approach."
- desc: Internet is a network that connects the world but the information flowing
    needs to be noticed. There are 57 signals google looks on further yahoo is a biggest
    news cite. Everyone form their an unique world of information. Social media is
    putting humans against each other by viral misinformation flowing over. As spaces
    shape behavior, we need digital environment that makes us comfortable and respects
    diversity.
- desc: 'In first video he made a point about algorithms that tailored to peoples
    personal preferences especially when its done without their consent but i think
    raised concerned are raged from past few years after USA election which proves
    how dangerous it could be the filter bubble.

    In second video speaker comparing the online space with physical space.A platform
    with strict policies and and platform the less strict policies all have their
    own pros and cons.Platform like facebook which led to have some bad result is
    also a powerful tool to raise your voice on controversial stuff.'
- desc: can you explain more details about the assignments and the blogs.
- desc: During my group's breakout rooms, one of the other students described what
    sort of things the "Filter Bubbles" videos talked about, and really I thought
    it was mostly just about targeted advertisements and such. These are already a
    sort of scary thing, researching something on your computer and seeing advertisements
    for those products on your phone later that day just scrolling through social
    media. After watching the videos though, I saw that it was really about a much
    bigger issue, not just changing the sorts of advertisements you get but actually
    manipulating the information you're able to find on search engines and news forums.
    I liked the quote they took from Mark Zuckerburg about how a squirrel dying in
    front of your house may be more relevant to your interests than people dying in
    Africa. It's the stuff that's right in front of our eyes and all around us that
    we really see, and that becomes even more of an issue when world information is
    tailored to the things that only apply to you because we begin to miss out on
    so much of the world, both the good and the bad that's going on unless it directly
    reaches us.
- desc: 'The Internet meant a connection to the filter bubble is our own unique universe
    of information that we live in online. Our filter bubble depends on who we are
    and what we do.

    The problem of filter bubble was discovered by some researchers and Netflix.

    We need the Internet to be that thing that we always want to be, we need it to
    connect us together, we need it to introduce us to new ideas, new people and different
    perspectives; we cannot achieve that if we live in isolation.


    The Internet is showing us what things we should see but not necessarily what
    we what to see.


    If the algorithm is gonna carry the world for us, if they are going to decide
    what we get to see or what we get not to see, we need to make sure all the algorithm
    is together in other to get a filter bubble'
- desc: 'The video provided me with deeper understanding of filter bubble. I agree
    with the video. I have personally experienced that social media platform presents
    information which they think I would want to look at. I see a divide between people.
    Many people on social media especially Facebook and Twitter believe in the propaganda,
    false claims, false news, hate speech etc that is shown to them. They are fed
    the information that strengths their believes and creates a filter bubble.


    In the last few years, it has become clearer to me that people are more divided
    than we think and this has been created by social media. I believe social media
    must take the responsibility to show all sides and not just feed similar information
    to keep people using their platforms. Social Media has huge influence on people
    and has huge power. It used be utilized to bring people together not to divide
    them'
- desc: 'Now is the era of big data. Because of the vast amount of basic data and
    more advanced algorithms, computers can easily distinguish a person''s information
    preferences and then accurately push the content he is interested in. For example,
    most website''s home pages are no longer random and cluttered but tailor-made
    for people, which has the advantage of making it easy to find the content you
    like to read. But at the same time, it also brings many problems; the first one
    is that people''s privacy or personal data may be leaked. For example, some companies
    may profit from users'' data. The second problem is that if the background pushes
    people''s favorite content for a long time, then the information people are exposed
    to is more likely to become a closed circle. In the end, people can live in their
    own world, which will make people become frogs in a well. For people, the progress
    of thinking and the renewal of knowledge often occur in the collision of different
    viewpoints. Just like listening to a debate match, if people only listen to the
    positive argument, people will more and more believe in the positive point of
    view and completely lose the spirit of doubt. Thus, While we enjoy big data''s
    scientific and technological benefits, we should always keep a clear head and
    have our own autonomy.

    Of course, social platforms also have a great obligation to the public. First
    of all, it is essential to create a healthy network environment. For example,
    children will also use social software when the social platform should prohibit
    some bad information from spreading on the Internet. Secondly, the social platform
    has a certain role in supervising society. If something unfair happens, the social
    platform becomes a tool for people to tell the injustice and get fair treatment.'
- desc: 'Discussion with one another as to what computing really means is one way
    of getting to know better what possible perspectives could be, in my group everyone
    was keen on discussing the topic put forth during the lecture i.e. What is computing
    and what is the need. Everyone in the group were more than happy to explain themselves
    and make their point on the basic computing that goes around the word on a day
    to day basis. It was a pretty healthy conversation overall.

    '
- desc: The first video talks about how the internet is being censored by the big
    companies to make it more personalized for us. In the 1950 we had the newspapers
    and editors as a gate keeper who censored what we could read and now we have the
    same kind of gate keeper who control what information we see and what information
    we don't and this is concerning because they're deciding what we should read,
    watch and listen instead of us doing it. The problem is that in 1950 the editors
    knew what was important they had some ethic but this is not the case for these
    computer algorithms. The second video is more about to what should we expect from
    social media and how they impact the society and norms.
- desc: 'In this class, we''ve been thinking about the computer age, and the TED video
    that we''ve been watching is about thinking about privacy.As the Internet tries
    to adapt to individual preferences, it will leave us in a filter bubble: our information
    will be limited to what we like, a phenomenon that is bad for us and for democracy.'
- desc: https://www.raps.org/news-and-articles/news-articles/2020/3/covid-19-vaccine-tracker
- desc: 'In this video of Filter bubble Eli Pariser talked about the most worried
    thing about the current era which is Privacy of an individual Person. As we can
    see internet is a great thing to explore the world however, it has some disadvantages
    as well.

    Nowadays Some applications such as Facebook are personalizing Internet for Individual
    but it has more disadvantage with compare to their Benefit. All the result behind
    that is we cannot get a truth though we have searched for that.'
- desc: "There are lot of things that I learned from this meeting. I will describe\
    \ in the upcoming paragraphs. The video (Beware online filter bubbles) describes\
    \ that how the information is flowing online. If we search anything from the internet\
    \ at the same time, our results may be different. This is because the google look\
    \ at different 57 signals, it depends on what kind of computer or browser person\
    \ is using and what is the location of a person. There is some kind of personalization\
    \ is done by the host companies. As Eric Schmidt said, \"It will be very hard\
    \ for people to watch or consume something that has not in some sense been tailored\
    \ for them.\u201D in a broadcast society, there were gatekeepers, the editors,\
    \ they controlled the flows of information. Internet allowed all of us to connect\
    \ together. We need to make sure what we see and determine what comes through\
    \ the filters. The video (What obligation do social media platforms have to the\
    \ greater good?) describes that behavior is shaped by the spaces (depends on its\
    \ designs). \_Eli Pariser describes climate change with change in the creation\
    \ of new systems and new equipment The social networking is becoming our future\
    \ place. Drawing inspiration from city designers and sociologists, shows how the\
    \ problems we face on internet technology are just not that recent expresses how,\
    \ by following the method of prospering urban centers, we could even generate\
    \ reliable social networks. Internet allows us to know about what is happening\
    \ around us."
- desc: There might be some issues on computer end but i think it can be minimized
    if there is proper education on how to use the computers security wisely such
    as not provide any information on websites which are not trusted i think most
    of the times its on users unawareness how information can be seen by third party
    users. I think if that part is resolved somehow the privacy concern would be much
    less
- desc: This meeting revolves around the topic of computing. Every individual has
    their own answer for the purpose of computing. But the most common answer to this
    question was that we can create websites or web pages using code and computers.
    Coding is everywhere, in every field. it has become an important part in every
    person's life.
- desc: If two person searches same thing at a time chances are they get different
    result by invisible algorithmic editing. That's a crazy thing to think that their
    is no original google anymore as each person has their tailored version of it.
    Hence we are witnessing the era where internet shows us what we want to see. You
    are in a 'filter bubble' where you don't decide what's in there, neither do you
    know what's left out. The editor's who initially controlled the flow of broadcast
    and now replaced by algorithmic ones in the internet which of course do not have
    ethical values.
- desc: 'Throughout this meeting, I was happy to be introduced to Eli Pariser''s term
    "filter bubbles." This is a phrase that I had not yet encountered and a concept
    that I had yet to ponder on my own. After watching Pariser''s TED Talks, I was
    prompted to think about the obligation social media platforms have to the greater
    good. Such platforms, which were once started to connect people worldwide, have
    now seemed to transform into online spaces for the consumption of entertainment
    and thus the production of profit. With this shift from education to consumption
    and entertainment, it is important to consider the role that filter bubbles play
    in shaping our perspective of the purpose of social media.


    With the personal tailoring of online experiences presented by social media algorithms,
    we as users often see what the Internet thinks we want to see, but seldom what
    we need to see. This includes opposing perspectives, challenging ideas, and experiences
    different from our own. In this way, filter bubbles isolate us in a "web of one,"
    shielding us from other walks of life. This can be extremely dangerous in the
    long-term, directing our thinking and behaviour towards a single story so that
    we oversimplify issues that afflict our world and are not exposed to new ideas.


    Exploring the idea of filter bubbles reminds me of Chimamanda Adichie''s "The
    Danger of A Single Story," linked here: https://www.youtube.com/watch?v=D9Ihs241zeg.
    Through this talk, Adichie explores the harm of looking at an idea, a group, a
    person through a single lens, demonstrating how filter bubbles can translate from
    the online to the real world.'
- desc: 'There were 2 videos for today''s lecture the first one was the ''Beware online
    filter bubble'' and the second one was ''What obligation do social media platforms
    have to the greater good?''


    In the filter bubble, it is shown how online search tabs work. How the online
    world collects our data such as our search history and based on our search history
    it shortlists what to be shown and what not to be shown. It is also mentioned
    in the video that the search result which we get are actually shorted by the algorithm.
    The algorithm is compared to a gatekeeper as it allows the selected amount of
    data to pass through the web.

    For example, if I am searching more related to the technical side of every aspect
    and one of my friends is searching related to the social side of every content,
    then if we search a word as simple as "News" we both will get the different news,
    I will get the news related the technical terms and my friend will get the news
    about the social terms even if we are using the same search engine. Same goes
    with the advertisement which is shown while viewing the sites, one will get the
    advertising related to its past search history. For example, if I want a new PC
    and I am viewing the BestBuy website then I will get its advertise while I am
    browsing for something different.


    While in the ''What obligation do social media platforms have to the greater good?''
    it was explained about the importance of social media in our daily life and also
    the disturbance it is making in our life. How different social platform is used
    to target different people in different ways. There is a need for an organized
    social platform and It explained how and what should be followed to create an
    organized structure of the social platform, from the example of the ancient village
    structures. It was also discussed how social platforms should be structured so
    that it benefits the daily life of everyone. It should be more public-friendly
    rather than only being user friendly. It should have more benefits than its drawbacks.'
- desc: "The idea of a moral framework in computing can create an interesting debate,\
    \ but it can quickly become boring when opinions follow a straight line. The idea\
    \ of right and wrong tends to be generalized in most circles when we are graded,\
    \ and consistently regurgitated to avoid scrutiny. At the end of the day, we do\
    \ we really care? The right opportunity or salary could easily sway someone\u2019\
    s opinion, and we all want something for free. How many people still have a Facebook\
    \ account and would be willing to pay a monthly subscription to remove ads and\
    \ alleviate their privacy concerns? It\u2019s all about the dollar bill."
- desc: 'This meeting was really productive and informative.

    See you in the next meeting.'
- desc: 'The things I learned from this videos are here

    filter bubbles :- I learned about the filter bubble is that there is invisible
    algorithmic editing in most of the sites like he said in the google example that
    google use the location, type of computer and which type of browser you using.
    In most of sites there are planned things like what they showing to us like in
    Netflix, they have already planned what they gonna show us on the screen and what
    next we have to see. And we didn''t see any editing on it.

    And there are many obligations on social media platforms like on social media
    the knowledgeful and helpful things are not shown or trolling but the things like
    arguments are in front of everyone''s screen people show their interest in these
    but not in knowledge quotes.'
- desc: 'the internet that we are using has clearly lots of pros ad cons and the list
    can keep going forever the first video the very important point i learned and
    its not debatle was the personalization filter, which is just a tiny part of the
    bubble filter and i think this is more dangereous because the knowledge regarding
    the web, internet, inforation is very less and itcreate chaos everytime something
    surafces.


    the second video of ted talk had some very good points and also which make sense
    about the structurely everything was build the more restrictions the more people
    tends to behave and the "Algorithm gatekeeper" from the first video can be a lot
    of used overhere in the idea of the real time soft critique which will not try
    to asses you but sort of a feedback will and i think can create a lot of difference
    in structurizing the space like facebook or twitter or any social media platform'
- desc: I am almost agreed with all about the filter bubble. We find ourselves in
    a filter bubble any time we're only surrounded by views and opinions we agree
    with, while being sheltered from opposing perspectives. Filter bubbles distort
    our understanding of the world and hamper our ability to make balanced decisions.
- desc: 'I learned about two things in this meeting:

    (1) There is a thing called filter bubbles that decides, what I see or don''t
    see based on the data social platforms collect from my daily usage.

    (2) We need better online spaces to interact because in future they may become
    our home to socialise. In order to achieve that we need better infrastructure.

    How exactly does filter bubbles decide what we don''t want to see?

    I would like to know more about the algorithm behind the information barrier.'
- desc: "This was about the filter bubbles. The user is only able to see the videos\
    \ of their interest. All user have various searches in the search bar, which represents\
    \ the field of their interests. Eli Pariser\u2019s concern regarding the info\
    \ that we see nowadays. However the second video was regarding the ted platform,\
    \ where people can colab in order share data or talking with friends in other\
    \ nation. Platforms like facebook, instagram and snapchat is the great example\
    \ of ted platforms."
- desc: "In today\u2019s lecture, we learned about how Internet make us feel like\
    \ we are in a filter bubble. They harness our input and show us the material which\
    \ they think is suitable for us from the data they have from our previous records.\
    \ On one side, it is remarkable how the internet shapes our life and on the other\
    \ side, it could be a danger for us.\n\nWe are still in stage where the technology\
    \ is still evolving. I am quite scared about how AI would evolve in coming years.\
    \ It is still skeptical how it would turn out in coming years."
- desc: "The question, Eli says, is that while the Internet reveals what we want to\
    \ see, we don't really need to see what we need to see. The filter bubble\_is\
    \ what he calls it. It's a bubble of exclusive knowledge of your own, so you can't\
    \ see what isn't going into it. It was seen as a liberation from the power of\
    \ people who owned and edited the content you saw when the Internet was created.\_"
- desc: The TED talk was very informative and a lot to know about. It is interesting
    to understand how the moral ethics are being violated in different part of the
    world using Web. The term "Filter Bubble" is affecting our world immensely and
    how one see stuff according to their own relevance.
- desc: In this class we learned about filter bubbles and how social media algorithms
    hide us from reality and news and promote products instead of giving us valuable
    information that might be useful to us for their own benefit. This was an individual
    gets habituated to this fake world and gets stuck inside this bubble created by
    these greedy companies for their own benefits. Which filters out the individual
    from the real world.
