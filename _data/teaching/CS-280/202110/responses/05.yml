raw: []
last_ts_read: '1611954276'
offering:
  id: CS-280-202110
cooked:
- desc: "I thought it was interesting how how limited the google algorithm really\
    \ is, I would\u2019ve thought the results would be more tailored to each person\
    \ based off of their history. I would be more interested in understanding how\
    \ search results are actually chosen and if they have anything to do with the\
    \ history of the device that is being used to search."
- desc: https://www.who.int/emergencies/diseases/novel-coronavirus-2019/events-as-they-happen
- desc: 'It appears that google search results are generated based on certain metrics
    such as: your location & ranking. A webpage''s ranking is probably determined
    by the amount of traffic on it as well as other unknown factors that are used
    by google''s algorithm.'
- desc: 'In our fifth meeting we discussed an article about trusting algorithms too
    much like only using the first result on the search engine Google. Google which
    is part of the Alphabet corporation has been known to sell user data and give
    internet residence to anti science, racisism and other dangerous ideologies and
    websites.


    Another dangerous endeavor that search engines and websites like Google and Facebook
    does is control what search results show for different people. Unless it is undeniably
    proven facts and science, falsehoods and controversal opinions can cause dangerous
    actions like denying Covid 19 exists, anti-vaccinations and violently trying to
    overthrow any government control.'
- desc: "Today we mainly discussed filter bubbles and how they affect search engine\
    \ results. The most interesting fact from today\u2019s discussion, in my opinion,\
    \ is the fact that different search algorithms generate different results. This\
    \ makes search engines, in and of themselves, their own little 'filter bubbles'.\
    \ People who search on Duck-Duck-Go, for example, will have a \u2018search engine\
    \ filter bubble\u2019 that is different than those who search for things on Google.\
    \ This can create differences in the information that people are exposed to while\
    \ searching the web. Used over a long period of time, this difference could create\
    \ entirely different knowledge bases between, for example, the people using Duck-Duck-Go\
    \ and the people using Google for their online searches. Taken to the extreme,\
    \ these different informational filters can influence people to develop different\
    \ fundamental opinions, creating cultural divides between people using different\
    \ websites for searching. I think this is important to be aware of on a personal\
    \ level, so that you are more likely to compare different search results from\
    \ different search engines and take the 'top' result from each website with a\
    \ grain of salt.\n\nRegarding content we see online, I think it's also important\
    \ to question the validity of what we read. You never really know if it's sponsored\
    \ content you're reading, a robot, or a real person. It can be hard to trust anything\
    \ online but we all do it because it's easier to simply trust than to do background\
    \ research and verify that what we are reading is true.\n\nThank you for reading,\
    \ see you all next class!\n\nDavid"
- desc: "I don't know if I necessarily learned that services such as Alexa use algorithms\
    \ to determine what information to give you, but the lecture made me think about\
    \ it more. Personally, my house utilizes Google Home and I find that there are\
    \ many benefits to having it. I've always considered the security and privacy\
    \ concerns \u2013 which is what I think most people worry about with \u201Clistening\u201D\
    \ devices \u2013 but I've hardly considered the biases of what information is\
    \ given. I think for innocuous things, such as a cookie recipe, it's not that\
    \ big of a deal, but services like this can unfortunately help enforce \u201C\
    filter bubbles\u201D previously mentioned in earlier meetings. This puts the onus\
    \ of fact checking or learning alternative answers on the user, which many people\
    \ are likely to skip for the sake of convenience."
- desc: "Alexa summarize\
    \ this article for me\u201D\n\nAmazon\u2019s Alexa is now answering to about 70%\
    \ of the total smart speaker market share within the United States. Amazon reporting\
    \ in 2019, that over 100 million devices of the AI assistant platform have already\
    \ been sold. It presents a unique opportunity to provide this sort of niche aid\
    \ to it\u2019s customer base. However, not all the reviews about Alexa are turning\
    \ out to be in favour. CBC\u2019s recent interview with Fr\xE9d\xE9ric Bouchard\
    \ reveals some of the woes of working with Alexa.\n\nBouchard states on how he\
    \ believes these devices eventually lead to the users finding fault with modern\
    \ science. How the unique algorithmic complexity of Alexa, often filters out key\
    \ points of information when asked for a specific topic based on the original\
    \ context.\nIt should be noted that Alexa is after all, an assistant. One should\
    \ not really need to delve the depths of the inner workings of society, political\
    \ thought, and other large discussions with something designed to provide quick\
    \ and easy answers. It\u2019s used as a household tool, like a quicker form of\
    \ Google Search. To dish out easy recipes and clear facts not fish out minute\
    \ details of the world\u2019s financial systems.\n\nWhile I think Dr. Bouchards\
    \ comments have precedence, it should really hold a better outlook of the user\
    \ than assume they will use Alexa as an honest answer to all key concerns."
- desc: I believe that this distrust of scientific expertise can be a good thing,
    if people in turn try to learn more information in the a proper way regarding
    subjects they do not quite understand. Especially since it seems like nowadays
    a lot of people just take anything they read or hear as facts immediately.
- desc: From the meeting5, I really like the idea of in-meeting activity. My opinion
    after reading the article discussed in the class is yes for sure asking anything
    to Siri or Alexa gives us answer but not with the all the information we used
    to get before. There are lots of reasons behind that it could be our location,
    past search history or anything. By getting the information what they wanted to
    give it to us that's completely wrong but on the other side if we see it's kind
    of advantage that we are not wasting the time and we are getting the best search
    result for what we are looking for. But I totally agree with Bouchard that in
    future if we can get access In a meaningful way that would be great!
- desc: "The past meeting was very interesting specially for me. As, when I study\
    \ something, I want to implement it in real life and that\u2019s what we exactly\
    \ did in the last meeting. We proved the existence of filter bubble by searching\
    \ same words and surprisingly majority got different top non-advertised results.\
    \ At first, I wasn\u2019t that interested in this topic, but after I practically\
    \ saw this, I want to know more about what criteria do this social-networking\
    \ platforms take into consideration, how they keep trace of specifics of participants,\
    \ and much more. Therefore, I surfed numerous websites in my spare time and I\
    \ encountered a book namely \u201CThe Filter Bubble: How the New Personalized\
    \ Web Is Changing What We Read and How We Think\u201D, which was written by Eli\
    \ Pariser who coined the term filter bubble. He listed all the facts about it\
    \ and their background in detail.\n\nThe most significant lesson I found about\
    \ \u201CHow Alexa is threatening society's trust in scientific expertise\u201D\
    \ is that while we always remain surrounded by individuals, we trust machines\
    \ rather than human beings. After having glance at it, I noticed that even I have\
    \ never taken the help of people around me for something different which I wanted\
    \ to know, and this proves that I'm more focused on science than on my friends\
    \ and family. Also, as Bouchard explains, it convinces me that this is still a\
    \ matter of concern. However, even I agree that this situation would change if\
    \ we all work together on it."
- desc: From the news article, I realized how some scientific products (voice assistants)
    facilitates distrust among people and restrains / hinders social interactions.
    I had never thought in any way that asking voice assistants for answers to some
    question can cause reduced interactions with people. I think the concerns raised
    in this article are valid and a really important topic that needs to be discussed
    to bring awareness to people that rely on voice assistants for answers.
- desc: 'I think the most interesting part of todays class was how similar the search
    results were between all the different users and browsers. I suspect that that
    either due to some websites being vastly more popular or that (especially with
    the political searches) there is some governing body enforcing a consistent result.
    eg) the ggc site being the first result for everyone on a Canadian network.


    I find it hard to believe that anyone would place very much trust in devices like
    alexa, as someone who has an alexa I can confirm that she either mishears, replies
    an answer to a completely different question than the one you asked, or straight
    up says "I dont know that one." for half the questions you ask her.'
- desc: "I like the involvement of everybody in this meeting about the filter search\
    \ bubble. However, doing this in class is quite a time-wasting, that could have\
    \ been a participation response where students go out and search for those keywords\
    \ and show their result.\nI would like a more in-depth explanation of the blog\
    \ post assignment as it's worth way more than the participation. Also, a breakout\
    \ room is good. Rather than having people just throwing out ideas left and right\
    \ is just too much to take in from over 100 people.\nThe Alexa\u2019s news.\n\
    Considering that once people let devices like Alexa, Google, etc. came into their\
    \ house, they would have absolutely no privacy at all. They always listen to your\
    \ daily activities to be tuned to your need. Because it is harder to go on a computer\
    \ and look up stuff, whatever more convenient. Honestly, this is making people\
    \ lazy than they already are. Based on the recent event with COVID-19, lots of\
    \ misinformation flying around. The amount of people not trusting in the news\
    \ is astonishing. Don\u2019t blame it on Alexa, blame it on social media and the\
    \ internet."
- desc: What I learned from our meeting today is that the electronic search algorithms
    in search engines do not give us neutral search results because they may be affected
    by different factors from one person to another or by the search settings from
    one user to another. In this pattern, I noticed that the differences in the search
    are sometimes a picture that is not pure or directed to the user, and this is
    something that is considered a subject to reconsider it because of its dimensions
    and effects on the neutrality of the search results.
- desc: 'Today in class we discussed how we implicitly trust the first result that
    the algorithm gives us when searching things on the internet. It was pretty fun
    to compare everyone''s search results and see what the commonalities were and
    also what the outliers were. It definitely has me reconsidering my choice to use
    Google, especially since my searches are usually mundane, and so there''s not
    really a need for Google to "curate" those results for me. Holla at me with your
    suggestions, haha. ;)


    Now that I think about it, I''m not even sure that Google is doing a good job
    of curating my search results in the first place. I do a lot of baking, and I
    look up egg-free or vegan recipes a lot (due to food sensitivities) and not even
    once has Google used that history to provide me with those results first when
    I do a general search. Interesting.


    I remember when I was a kid and sometimes you would search something on a search
    engine and you wouldn''t find what you were looking for until like, seven pages
    in (or more). Sorting through the results yourself was just part of the deal.
    Nowadays if I have to go past the first page of results, I''m like "OH MY GOD
    DOES IT EVEN EXIST?" Also, usually you would have dozens of pages of results,
    sometimes hundreds. I''ve noticed recently that Google now only gives about a
    handful of pages and once you reach the end, it usually gives you some blurb about
    filtering due to relevance.


    I do think that in some ways the reputability and legitimacy of the first results
    have improved greatly (I mean, I remember googling telekinesis on AskJeeves when
    I was like 9 and trying to teach myself to bend a spoon with my mind from one
    of the articles I found), but I also think that the tendency to question those
    results has definitely gone down. I also think it''s worth noting that a lot of
    the top results on Google are paid - I know that the salon I used to work at paid
    some kind of subscription so that they would come up first when you looked up
    "best salon in Regina" (I''m not sure if they still do, though, or if you can
    be outbid on that, or how that even works, to be honest).


    The problem nowadays is that I think a lot of people equate Googling to researching,
    when they are not at all the same - being critical about the search results you''re
    getting, although it has always been important, is seeming more and more so as
    time passes.


    '
- desc: 'When looking at "How ''Alexa'' is threatening society''s trust in scientific
    expertise" people do have a right to be skeptical of technology algorithms, as
    it is impossible to know what is going on in them for the average person. A study
    done in "https://www.cbsnews.com/news/mortgage-discrimination-black-and-latino-paying-millions-more-in-interest-study-shows/"
    showed that black and Latino applicants paid 0.08% more than white people. These
    biases from computers come from the data that they are learning from. Since people
    have biases the computer learning from them will also have a bias.


    Politicians saying they are on the side of science has been a political issue
    for longer than Alexia. With the vast adoption of the internet we have seen information
    spreading faster than anyone could control it. The fastest way to spread information
    is to make people angry about the content so they share it. Far less people will
    share happy news then they will share ''feel good'' stories. This is inline with
    social media algorithms because it is how they generate ''clicks'' for content
    and advertising sales. This came along long before politicians started saying
    "I''m on the side of science". Misinformation has been the use of big companies
    to keep their interests a priority. People don''t spend enough time scrutinizing
    things that they hear, people believe rich people have the interests of the public
    at heart when most times they do not. They just want to believe it and need something
    to fight against. This makes it easy to go against science as arguing against
    it is an easy fight to start.'
- desc: I learned a bit concept about google algorithm. I would love to learn or study
    on google algorithm how it works and how it ranks the result.I researched a bit
    and found out that google works on ranking algorithm. The results which are shown
    are due to the following factors :-the key words you typed,the location where
    you are in,you past history to get you to more fimilar topic like if someone searches
    gate then for normal person it would be image of a gate nd meaning nd definition
    for it but if some person which is more related to physics amd have searched many
    times on physics topic then google will google him logic gates and finally the
    most viewed or visited links or webpages get the first priority.So these was my
    research on little bit how its algorithm works but would like to know more about
    it
- desc: 'When we did the in-class filter bubble google search activity I thought it
    would be interesting to do a small test among myself and my family by checking
    2 additional sources (an iPad that I use for schoolwork and an old iPhone) as
    well as the original source of my PC. The result was kind of uninteresting as
    there was only one difference among the 3 sources, which was the "chocolate cookie
    recipe" search, which had a new top search on the old iPhone being: https://www.bettycrocker.com/recipes/ultimate-chocolate-chip-cookies/77c14e03-d8b0-4844-846d-f19304f61c57
    (the third top search on the PC and iPad). My additional results gives my the
    impression that google searches does not seem to differentiate greatly among some
    users as my google search experience among 3 sources are exactly the same as each
    other (or very similar) and exactly the same (or very similar) as the ones that
    we found in class (my searches match a large majority of classmates). Of course
    a larger scale look at searches would be needed to see the effect of online filter
    bubbles and google searches but early evidence seems to suggest very similar results
    for a large majority of users (at least if the users are from the Saskatchewan
    region - VPN usage to alter location seems to alter the search results as we found
    in class).


    Additional testing suggestions: 1.) Be login to a google account (google might
    have more data on you and thus could curate searches to cater more to you) which
    might alter the google search results the user sees.

    2.) Repeat the experiment in other search engines to possibly find trends (its
    possible that other search engines do not provide the same homogeneous search
    results we found for a large majority of users in our test).'
- desc: It is because AI doesn't discriminate that's why we don't get much different
    results but it may vary from locations to locations basically it uses the data
    gathered from users pattern which site was more clicked after searching particular
    word or even the interest of the user can be noticed by the search engines.
- desc: 'From past meeting 5, I learned how the search engine shows different results
    base on your location, domain, IP and type of search engine. If you search for
    "some recipe" in google.ca the result will be different with https://www.bing.com/
    and different in https://ca.search.yahoo.com/. Also if you have your location
    service OFF then it will show you what comes first in the search then if you have
    it ON. It will show something close to your area/region.


    We did this filter bubble experiment most of the class to see how it works.'
- desc: "In the past meeting Dr. Hepting talked a bit about the blog in the class\
    \ and the submission details. Also talked about the meeting details and the expectations.\
    \ In the meeting We also read an CBC article about \u201CHow 'Alexa' is threatening\
    \ society's trust in scientific expertise\u201D. Which was about how human are\
    \ so biased and their trust toward the machine over a human. When we are searching\
    \ for a recipe by using voice assistance, the siri or alexa providing us a random\
    \ recipe. But without knowing if the recipe is accurate or watching the video\
    \ or article we are relying on that. We are not even giving human a chance for\
    \ discrimination, where they might have more appropriate information. The author\
    \ suggests us to trust more on human than a machine in order to do social interaction.\
    \ Beside reading this article we also did experience on filter bubble to see how\
    \ different individual gets different search results. I found this very interesting\
    \ and fun. From the past I have learned that we are too much depended on scientific\
    \ devices which is lacking our social interaction day by day.\n\nthe other day\
    \ I was watching a video and I found it very interesting. Its about how what\u2019\
    s app are causing security breaches but we are still ignoring this fact and keep\
    \ using it. Hope you guys enjoy this informations too. Here is the link: https://youtu.be/JZOks_SuFtA"
- desc: In class yesterday we discussed VPN's and how based on where you are will
    affect your search results. One thing that I struggled to understand is just how
    big of a difference there is on what our search results end up being based on
    where we are. I know that different places revolve around different cultures but
    things as simple as a cookie recipe can greatly be changed simply by being in
    different spots and having different advertising history.
- desc: "In meeting 5, we are doing in class activity to search some topics by using\
    \ google. It lets us understand when we search same topic at the same time, we\
    \ will get almost similar website from google.\n\nFor \"beware online filter bubbles\"\
    :\nWeb companies will adjust services according to people\u2019s personal preferences,\
    \ like different people search same item at website, the output of results are\
    \ total different. We hope that the web company can let everyone set their own\
    \ personal preferences.\n\nFor \"what obligation do social media platforms have\
    \ to the greater good\":\nSocial media is already indispensable for everyone.\
    \ We can learn about the latest news or news happening around us from the Internet.\
    \ Anyone can post a message on social media to let others know you more fully."
- desc: I thought it was interesting that we had a wide range of search results for
    different topics. My theory is that it was based on the search engine used (google
    vs bing vs duckduckgo), and also maybe location services. The covid vaccine result
    that was the most popular was really strange to see because I assumed it would
    all be official government pages or perhaps even news articles.
- desc: 'I learnt from the video that from social psychology, spaces shapes behaviour
    and that spaces have political consequences. When people are in a big room, they
    tend to behave differently than when they are in a small room.


    Spaces change behaviour partly because of how they are designed or by how they
    are encoded or norms on how to behave.


    Good physical spaces are structured.


    The behaviour of LinkedIn tells that it is a work platform'
- desc: In the past meeting, we learned how we get different search results depending
    on our internet footprints. The concept from the last meeting that was difficult
    was understand was the fact that to what ratio does the SEO and to what ratio
    google's algorithm contributes to the search result for an individual. I would
    definitely want to learn more about that. The fact that some search results were
    not even relevant to the search was disturbing ( for example COVID-19 Vaccines).
    I had an experience with this myself. If searched Ice skates they would show me
    male ice-skates ( I'm a male) but when my roommate which a female searches Iceskates
    they would show up women's figure skating ice skates. This proves how they personalised
    your search results, but sometimes the ads remain the same and hence we don't
    know they show us result based on our data or when they would show us ads.
- desc: 'I didn''t really understand the purpose of the in-class exercise of posting
    the links we got from various searches to see how they differed from other people''s.
    Most people seemed to get the same two or three links at the top of their results.
    The CBC Ideas piece about chocolate chip cookie recipes isn''t really about why
    certain users will see one link and other users will see another link. It is more
    about what is the process for determining which recipe is chosen by the algorithm
    and who or what is responsible for this determination. Dr Bouchard argues that
    by delegating tasks to a machine that we would have previously requested from
    another person we are slowly degrading the trust that we have in other people.


    The general idea that Dr Bouchard brought up in CBC Ideas piece is similar to
    the one brought up in the Anomie TED Talk video by Eli Pariser. In this video,
    Pariser proposes that technology platforms should be modeled after cities, that
    there needs to be some form of digital urban planners and architects. The problem
    with this idea is that cities are public and people pay taxes to pay for services
    that make a city a nice place to live. Corporations have shareholders who are
    mostly concerned with profits. So if we can agree with Pariser that changes needed
    to be made with how these platforms are operated, how do we convince CEOs of these
    mega tech corporations to do this? Political mandates would likely not be very
    popular in the USA where all these corporations are headquartered. Maybe government
    grants for good social design of platforms. Incentives like these could give a
    leg-up to new startup companies willing to do this. But then who determines what
    is good social design? The article and the video from class do a good job explaining
    why these problems exist and give some basic ideas of how they may be solved but
    it is difficult to imagine any real change happening any time soon.


    '
- desc: During this meeting, a majority of our class was spent in doing a search experiment.
    The topic of the videos we had to watch was about Filter Bubbles and how they
    are leaving out objective important information in favor of subjective important
    information. This was evident from the results of the experiment. For example,
    we were asked to search about the Governor General of Canada. The top search results
    didn't show any recent news about the resignation of the General, however it led
    us to the website giving us information about what the General does. It isn't
    only about this specific news, if you go and search about Iran, based on where
    you live and what your previous engagement with browsing about critical things
    is, you will get vastly different results, ranging from the war going over there
    to information about tourism, solely based on your browsing patterns. Depending
    on what links you click, you will be shown more politically conservative or liberal
    posts. This results in people getting only one side of the story and getting polarized
    about it. There has to be some kind of control that the individual has about what
    they want to see in their feeds. If they knowing choose not to receive certain
    type of information, that's okay, at-least it was their choice. However, the fact
    that right now, the algorithms are deciding what we should and shouldn't see/read
    about is unnerving.
- desc: what i am most interested in learning more about is what the possible alternatives
    to algorithmic filtering would be. sure filter bubbles are not ideal but neither
    is having our search results curated by a corporation. To me this problem might
    be on the consumer not the program and an greater emphasis needs to be put on
    become active consumers of internet not just allowing the algorithm decide for
    us.
- desc: "Vyomesh\n\n\_\n\nHow \u2018Alexa\u2019 is threatening the society\u2019s\
    \ trust in scientific expertise.\n\n\_\_\_\_\_\_\_\_\_\_\_\_\_\_\n\nHere we learn\
    \ about the reason about the working of the Alexa is quite interesting but somehow\
    \ it is good for the someone as per their ideology or for someone it is not. The\
    \ Alexa or any other devices that runs with the new technology known as Artificial\
    \ intelligence. It records the voice, tracks our location, and customize things\
    \ according to ourselves. It captures all the moments of ours so it could be dangerous.\n\
    \nHypothetically speaking there could be a breach that can carve out the important\
    \ details of ones and can be used for personalization or anything. It can be used\
    \ for illegal activities as well. So, trusting this gadget is an ongoing issue\
    \ in one\u2019s mind.\n\n"
- desc: 'The search engine activity we did in class was an interesting example of
    how we may be limited in our scope of what we can easily learn about, and it also
    showed how search terms can drastically effect what actual web searches come up,
    vs News Articles. It showed that we can, providing we are in a similar geographical
    location, get similar, repeatable results. However, this limits the ease of access
    to a variety of sources of information or views, and also creates a feedback loop
    depending on how the algorithm works, where the popular result gets picked more
    because it is popular, and because it is popular it gets pushed towards or remains
    at the top. Another interesting thing I noted was the specificity that was required
    for some searches, such as the Governor General search, where if we didn''t add
    in anything to specify timeline, context, or names, nothing was brought up regarding
    the recent resignation.


    Given, this was all just doing a web search. Regarding relating it to previous
    classes, it is highly likely that many of our targeted ads on social media are
    keeping us in this feedback loop, where we are shown things that we agree to and
    have to intentionally try to break out of it to find alternative sources, if that
    is something the user even had any desire to do.'
- desc: I found the results of our class experiments on search results interesting,
    and was honestly surprised to see that for most searches, one or two URLs seemed
    to account for the vast majority of results. I wondered to what extent the top
    search result for each user was influenced by their location and browsing data,
    and how much of it was influenced mainly by the search engine used. A couple of
    years back, privacy concerns led me to switch search engines, as I was becoming
    unsettled by how relevant my search results were to my interests. It seems strange
    to criticize a tool for working too well, but I found the search engine's algorithms
    unnervingly good at determining what I wanted, and I didn't like the idea of a
    corporation having that kind of knowledge about me. Since switching to a search
    engine that prioritizes privacy, I feel much more comfortable about my control
    of my personal information, but I can't deny that the search results I get on
    my new service of choice are generally much less relevant, and that in particular
    the search engine I use now is much worse at finding relevant results from more
    obscure sources. I suspect that when it comes to data-driven applications such
    as search engines, there will always be a trade-off between functionality and
    privacy.
- desc: 'Meeting 5 was interesting, i was little bit surprised to see different results
    upon searching same thing, even after being in the same area. the last meeting
    proved that there is really such thing like filter bubble.

    but the concept of alexa being a threat to society is little bit difficult for
    me to understand. but yes, it is true that filter bubbles are the threat. the
    internet should be the platform providing immense and same crucial knowledge to
    everyone. it should not be on the basis of recent search or what internet thinks
    that we want to see.'
- desc: The filter bubbles are threat as same as alexa to society. the internet is
    showing us the results that it thinks we should see. Upon searching same topic
    people are getting different results, which is the result of filer bubbles. This
    meeting was all about getting different results upon searching same thing.
- desc: This meeting was sort of interesting, using different web browsers to search
    various information, the 'Chocolate cookie recipe' and also various political
    affairs, We all wondered what the basic criteria would be for the web browser
    to provide us with the results that are mainly similar but also differentiate
    as we surf on contrasting web engines.
- desc: 'the internet that we are using has clearly lots of pros ad cons and the list
    can keep going forever the first video the very important point i learned and
    its not debatle was the personalization filter, which is just a tiny part of the
    bubble filter and i think this is more dangereous because the knowledge regarding
    the web, internet, inforation is very less and itcreate chaos everytime something
    surafces.


    the second video of ted talk had some very good points and also which make sense
    about the structurely everything was build the more restrictions the more people
    tends to behave and the "Algorithm gatekeeper" from the first video can be a lot
    of used overhere in the idea of the real time soft critique which will not try
    to asses you but sort of a feedback will and i think can create a lot of difference
    in structurizing the space like facebook or twitter or any social media platform'
- desc: "For the last meeting, we reviewed the content of the student blog, and analyzed\
    \ how the google search website gave us the feedback of the content that we want.\
    \ As can be seen, some students give very different links for the topic, and other\
    \ students give the exact same link of the topic. So, we can say, there do have\
    \ a filter bubble on google search. In addition, we read an article on the CBC\
    \ site, about \u2018\u2019How 'Alexa' is threatening society's trust in scientific\
    \ expertise\u201D. Here are some of my point of views.\nthe most important thing\
    \ you learned from this past meeting\nNowadays, society has lost trust to scientists\
    \ who design the AI robot. Because, when you ask for some information you need\
    \ to the AI, It gives you the feedback that is not what you need, we can see how\
    \ this occurs when we search the chocolate chip cookies during our class. As Fr\xE9\
    d\xE9ric Bouchard, a philosopher of science, the crisis issue is people lose trust\
    \ to scientists, and even doubt the society. Sometimes the politicians unintentionally\
    \ break the trust from society to science, by suggesting words like using technic\
    \ is personal choice or anti-science. In conclusion, how to redeem people\u2019\
    s credibility for science is a big issue in our current society."
- desc: The most important thing that I learned from past meetings is that how we
    humans trust more on artificial intelligence rather then on our own fellow persons.
    The concept from the past meeting that was the most difficult to understand was
    when we all experimented to searched chocolate chip cookie recipe and we all got
    different recipe results. We all clicked on the first recipe without even thinking
    that how this recipe came up on our web. A philosopher Bouchard is searching on
    this concept and he is worried about the increased reliance we humans show on
    artificial intelligence. After I got my answer from internet I haven't thought
    to look up on the answer that is it correct or not but simply trust on it. As
    humans are biased and the artificial intelligence is less biased in some way so
    we trust more in computers than our human kind. Due to this humans show no interest
    in scientist. I hope that in future instead of searching a chocolate chip cookie
    recipe on internet we should ask each other to maintain trust on the people around
    us.
- desc: 'Learning about filter bubbles and how they work was sort of interesting.
    We really do need to have a common search platform where everyone gets the same
    news and the same result.

    Getting to know the search results of everyone and how they differed from one
    another even though everyone searched for the same thing at the same time was
    amusing. Looking forward to having more activities of this kind.'
- desc: It is horrible that technology is taking over our privacy and even though
    software or a website says it protects our privacy, in some ways, it is being
    leaked or stored somewhere in the information bubble. It hit me when Eli Pariser
    said that the internet is showing us what we want to see, however, it is not necessarily
    what we need to see. The algorithm all the search engine use includes our personal
    information. So it feels like the human gatekeeper has been replaced by with the
    algorithm ones.
- desc: "\u2022 the most important thing you learned from this past meeting\nhow big\
    \ tech giants use your search result, location to filter what do you see on the\
    \ web.\nwhat you would like to know more about\nI want to learn more about how\
    \ this companies uses our data and our preferences to filter our search result\
    \ and how can we escape it.\n\u2022 something you encountered that is related\
    \ to the past meeting\nI read this great article\nLink: https://www.nbcnews.com/better/lifestyle/problem-social-media-reinforcement-bubbles-what-you-can-do-about-ncna1063896"
- desc: In our last meeting we discussed and saw the bubble effect firsthand from
    different perspective, or ip address to be more precise. How our location and
    other stuff impacts on what news or search preferences we get. As we saw 2 videos
    prom Eli Pariser from the ted talk of previous class, we discussed the topic of
    those videos in class and its impact on society
- desc: I was expecting the links that showed up on google to vary quite a bit. However,
    it was interesting to see that the links were largely consistent for all the searches
    that were performed during class, with 2 to 3 main first links showing up for
    most users. I assume SEO might be at play here on boosting those links to the
    top. Additionally, I believe that if more controversial topics were chosen, there
    might be a larger variety in the search results.
- desc: In the class meeting, I learned about Forticlient and algorithms. Forticlient
    is a VPN, and it is a secure and reliable to access networks and applications
    of networking gadgets. Then, Artificial Intelligence algorithms like Siri, Alexa,
    Google, etc., society relies on them and losing trust over the organization and
    human expertise. Bouchard said, "we can't see what we want, "which means if we
    search over the internet, it shows we have the content over the platform which
    the algorithms want to offer, and we studied on it to know that what will happen.
    Our first attempt on Chocolate Chip Cookie recipe then Governor-General of Canada
    and Covid-19. Vaccine to check the results, and most of the URLs were the same
    as per algorithm features; that is proof, applications can provide us only such
    data what they want to show us.
- desc: I see how the technology behind Siri and Alexa can be difficult to trust,
    when they deliver information without any source along with it. When using google
    on a computer, it is much easier to check the website or author of a source to
    test its credibility. I think it is just important for users to understand this
    difference. I can understand how this could create a lack of trust in technology
    and algorithms, but I think its unnecessary. The technology like Siri and Alexa
    that we have is very useful in everyday life, and should not cause any problems
    as long as it is used properly.
- desc: The most interesting part I found during this meeting is when I using Microsoft
    Bing to search the "Chocolate Chip Cookie Recipe", the top 5 result is different
    with google, and I use google more often. I think the different between the two
    search result is because the data that google collected from my search history
    is more than Microsoft.
- desc: After watching the Don Norman talk , I found the most imporant topic to be
    the Norman's point on happiness and stress. When people are happy they are often
    relaxed, and when people are stressed they are often anxious, among other things
    of course. Although anecdotal, personally I always found myself doing significantly
    worse on exams that I was overly stressed about. More so in my first year of University
    as that is when my "exam anxiety" was at its highest. The past two years however,
    I have been taking a more relaxed, laid back approach; because eventually I did
    come to a realization that as long as I tried my best, whatever happens is going
    to happen. And that definitely changed my perspective. Now it's not like im "happy"
    doing exams or anything, I think thats something I share with most students, but
    I am relaxed and far less stressed doing exams. I'm not sure about the science
    behind it but I think Norman may be on to something, because my grades have never
    been higher.
- desc: 'The point that I find interesting in this lecture was that I never thought
    about how virtual assistants

    are getting their results and how they might be delegating our judgment.'
- desc: '1.As discussed in class, filter bubble can be a problem because it shows
    the information that people already belief in (bias ideals) instead of different
    ideals, by reading the news, technology such as Alexa or google may cause problem
    because of humans way of thinking. moreover i believe google, alexa or others
    record our history, location etc and remembers them, Shows us what information
    according to them not what people wants to see.


    2. can your go over the topics of assignment 1 one more time??'
- desc: 'In the last lecture we had learned about how alexa and other algorithms like
    this are threatening the trust among the people. Without seeing the source from
    which we are getting our answers, weather it is correct or not. We trust the first
    answer that pop up.


    We also learned about filter bubble in class today with few examples and we got
    to know that we get different results when we are in different part of the world
    but when we are in a same area or city the result seems to match mostly.'
- desc: The most important thing that I learned about last meeting, was filter bubbles.
    The speaker explained it at one point during his talk that it was invisible editing
    of the web. This obviously brings up questions as the intent to these edits, the
    affects they have, and the possible abuse of this editing that can affect all
    those visiting certain parts of the web. There is also a discussion to be had
    about personalization vs. manipulation. There are obvious benefits to personalization
    of search results or Facebook wall results. However, there are issues involving
    what can be shown and should be shown. Not only that, but the algorithms can make
    mistakes, causing people to miss out on essential, or the right, information.
    Put simply, internet could be displaying what we want to see rather than what
    we need to see. I would love to learn and see direct examples of filter bubbles
    affecting my life, and the flow of information. I would also love to learn about
    the ethics that go into what should be shown to or consumed in our information
    diet. I for one have totally noticed my filter bubble when browsing Netflix, or
    more obviously, YouTube. I feel like I can easily be influenced if I consume many
    types of media that present similar thoughts or ideologies. There is power, ethics,
    and discussion in filter bubbles and was very interesting to dive into.
- desc: This class was rather interesting as it was an experiment of sorts. The main
    takeaway is that there appears to be certain sites that bump themselves up as
    the number one result, regardless of who searches for it. I have an interest in
    cooking, and in spite of that I still got one of the same two results (all recipes
    and Sally's baking addiction), my past history and websites that I visit was nowhere
    to be found, making it quite curious. Looking more at it, they are both highly
    rated recipes, with all recipes having a 5 star rating based off of 17,760 ratings
    and Sally's baking addition recipe had a 4.9 rating based off of 239 reviews.
    Perhaps that was a factor in them showing up? It is funny nonetheless. The search
    of the Governor General was very normal, and not really that noteworthy. The most
    perplexing thing was the search for the COVID-19 vaccine, which for lots of people
    brought up RAPS as the top search result - an organization that I had never heard
    of until this class. In my opinion I feel that for things such as COVID-19 Google
    (or Bing, or whichever search engine you're using) should have more of a curated
    result showing authoritative sources -- such as the Government of Canada, Government
    of Saskatchewan, or even the World Health Organization. If anything just to fight
    off misinformation. It was a really fun class though, and it would be interesting
    to learn more about how these search algorithms work.
- desc: 'The video shows how our environment effect our behaviour and thought process.
    How the online platform that we are son much involved with and depended on can
    be beneficial to us beside being destructive. The video further goes on to describe
    how the civilization of past ideas were for our betterment and how we are moving
    towards a generation confined in man-made online space leaving behind the best
    behavioural and personalities that we could have gained instead.


    The article about alexa shows how our daily security is threatened with the rising
    blind dependence and trust on technology. Technology is day by day imprisoning
    us and our creativity.'
- desc: 'I think its important to note from this past meeting is that it is up to
    the user to judge whether the source they searched is a reliable source.


    the concept from this past meeting that was the most difficult to understand and
    would like to know more about is how some sources acheived to rank 1st; Also,
    why Google showed the same result for the chocolate chip cookie recipe for some
    people but not for others? why for some people it''s the same 1st ranked site
    but not for others?


    something you encountered that is related to the past meeting I think is that
    filter bubbles but I would like some more info that would help me with some of
    the questions I have.'
- desc: In last lecture, we had a discussion and lot of experiment that how google
    gives different results to individual for the exact same question. It means these
    kind of search engines are personalizing data for individual and providing results
    according to that. We can get example that I tried to search about Samsung S21
    from my device so it was showing me first link from official Samsung while I tried
    it from my friends device so first link from bell network with S21 instead of
    Samsung. Hence we are unaware that whether it is the SEO of the website or Google
    personalizing our data?!
- desc: in the lecture we all searched about different things( ex- chocolate chip
    cookie recipe, covid 19 vaccine and more). The search results was different for
    everyone. This is because of internet is using invisible algorithm to personalize
    the data. It depends upon the searched history, what kind of browser user is using
    and the location of user. Internet does not give the results that what we want
    to see ,but it gives the information that internet wants that we should know;
    means it is putting filter bubbles. Eli Pariser makes the argument that this might
    yield results to be terrible for us as well as bad for the country.
- desc: In the last lesson, I learned how easy it is to get information in the era
    of big data. No matter what it is, just enter it on the Google interface, and
    the content you want to find appears. However, the difficulty of filtering out
    useful information from the massive amount of information has also greatly increased.
    Especially the increase of useless information caused by current consumerism,
    such as various advertisements. I think the most difficult point in this era is
    how to obtain effective information and distinguish the true and false information.
    In some cases, the information found after spending a lot of time may be wrong.
    In some cases, the information found after spending a lot of time may be wrong.
    In future lessons, I want to know more about finding information on the Internet.
- desc: "I read the article about Alexa again and found it interesting how some people\
    \ can draw a line with gadgets like these, after all, we all carry a smartphone\
    \ in our pockets. It was also a little entertaining how the headline targets Alexa,\
    \ maybe the author of the article was really upset with his last Amazon purchase.\
    \ Anyways, the \u201CHope for the future\u201D section made me think.\nFrom the\
    \ article:\n\n\"There'll be an energy in trusting in each other and building things\
    \ together,\" he said. In this way, he sees the pandemic as a kind of necessary\
    \ reckoning that will ultimately improve trust between people.\n\nWrong! I\u2019\
    m sorry, but is the article really trying to end on a positive note in favour\
    \ of a global pandemic? While I can appreciate the attempt to find something positive\
    \ out of a horrible situation, let us at least agree that nothing good came out\
    \ of this, except for the chosen few that found themselves in a more comfortable\
    \ situation than before."
- desc: 'In todays meeting we talked about many thing related to Filter bubble the
    video is linked to the in-class activity which is due to the filter bubble is
    a algorithm whose outline includes ones personal information online and the bubble
    inside contains ones human behavior individually which is totally different from
    others. The last part is to request some controls for the user to have some authority
    through filters and which is some risk.

    The risk in platform of social media is getting more riskier daily. The bullying
    and digital harm through social media has increased. So, the obligation that social
    media platform has is the structure spaces for the greater good and the lacking
    of norm (i.e the Anomie), make products public-friendly. Finally, the digital
    environment obligation to relate the actual human physical environment.'
- desc: 'In this lecture, we learned how we get a different search result in spite
    of searching the same thing but over the different devices as it uses the past
    search history to make the experience better. In the lecture, we all in the lecture
    searched on the different topics such as the Chocolate chip cookie, Covid 19 Vaccine,
    Governor-General of Canada. We all searched for the same topic but we found that
    the advertisement which was shown to us were different due to the same reason.

    I also had an experience like this I and my roommate searched for the term ''Samsung''
    on the google chrome but we both got a different search result I got"https://www.google.com/search?rlz=1C1CHBF_enCA916CA916&sxsrf=ALeKk00TDhZCAEtqSeIMYAVbC63GnLhzfg%3A1611805077006&ei=lDESYPr3PMPc5gKJ74PADQ&q=samsung+phones&oq=samsung&gs_lcp=CgZwc3ktYWIQARgBMgQIABBHMgQIABBHMgQIABBHMgQIABBHMgQIABBHMgQIABBHMgQIABBHMgQIABBHUABYAGDdS2gAcAJ4AIABAIgBAJIBAJgBAKoBB2d3cy13aXrIAQjAAQE&sclient=psy-ab"
    and he got "https://www.google.com/search?q=samsung+phones&rlz=1C1CHZO_enIN925IN925&oq=samsung+phones&aqs=chrome..69i57j0i433j0j0i433j0l2j0i395j69i60.7907j1j7&sourceid=chrome&ie=UTF-8"
    although we were on the same wifi.

    It was very interesting to know the reason behind that; also, he was shown different
    types of adds, and I was shown different types of adds.

    He was getting adds related to the games and I was getting adds related to technology.'
- desc: After watching the most recent videos posted, it made me think about the power
    of design and it's affect on us consciously and subconsciously. The power of our
    minds to affect our actions based the environmental stimulation around us. When
    we are happier we perform better, but at the same time we need structure and order
    to get things done. In the first video it is very apparent that the way things
    are designed affects our emotions. This definitely plays into programming a website
    or space, we can see the effects different designs have on peoples emotions. The
    second video was very powerful as well, talking about the psychology of phobias
    and judgement. Also the power of thinking creatively and how it can help people
    live a more fulfilling life. We can tie these two ideas together to think about
    a design that inspires creativity from the users to create a more fulfilling life.
- desc: In this meeting I found the filter bubble experiment very interesting but
    I also want to know that why we did not get the same result as shown in the video.
    Most of the people got similar search results then where is that filter bubble
    thing?
- desc: The point 'Alexa' is threatening society's trust in logical ability is interesting.
    these days individuals are occupied with their devices like smartphones, PC, and
    so forth talk remains with individuals. in this subject, we can see that Bouchard
    is stressed over people. since individuals trust the web more than people. The
    web runs on calculations and all web-based looking is refined through them. Indeed,
    all that individuals see and do on the web is a result of calculations. individuals
    can look and get the data about the thing they are searching for and see better
    while taking any choices. be that as it may, the worry is the data they look for
    is how many sets in stone since we can't see the connection or any definition
    identified with it. on the opposite side on the off chance that we need any data
    about something we can get some information about it we can get it from the experienced
    people around us with 100% guarantee yet the issue is individuals trust logical
    aptitude more than people. this thing individuals need to comprehend and accept.
- desc: 'Similar to videos I watched in the previous meeting(meeting 4), I learned
    from this meeting that not everyone asking the same question/query to google gets
    the same answer.


    I would like to know more about how the ranking of the results that google provides
    effects/affects a person''s decision making process or understanding of a subject.'
- desc: well, from the last class topic and by watching the videos related to that
    class we get the information about the filter bubbles that how filter bubbles
    working as in last class we doing some search on google and that means that by
    doing this we get the information about the filters as we all were doing a research
    and that research shows that everyone get different different top results as the
    reason behind that is the filters the software they run for the searching of us
    then the location is the thing that matters so we can say that when we search
    anything then our location is the thing that matters And we can also defines as
    the when a website algorithm selectively guesses what information a user would
    like to see based on information about the user, such as location and search .
- desc: In our last meeting, i got to know and learn about the way we will end up
    getting distinct search results which actually is based on put internet tracking.
    The previous meeting's theory was tough to understand about the ratio thing between
    algorithm of google and SEO. Google's Algorithm imparts the search results differntly
    for each and every person. So everyone might have their unique search result.
    Also, some people may experience irrelevant search results. At times pops up the
    same advertisement all the time. Hence, the search results are individualized
    by them. Therefore, we cannot say any specific thing about this cause the google
    team doesn't announce how they've shown us these results, it might be because
    they fetched our data while showing the advertisements.
- desc: "During last class, we got to know more about filter bubble. We searched about\
    \ Chocolate chip cookie recipe, Governor of Canada and COVID-19 vaccine. Few people\
    \ from our class got different results. We tried figuring out the reason behind\
    \ getting different link. This was based on the algorithm used by search engines.\
    \ And we don\u2019t know what algorithms are used by these search engines?\nThe\
    \ lesson I have learnt from \u201CHow 'Alexa' is threatening society's trust in\
    \ scientific expertise\u201D is that we don\u2019t have trust among each other.\
    \ Usually, whenever we face some problem in our real life, we take help of Google,\
    \ Bing or any other search engine. Instead of doing this, if we ask for help to\
    \ people around us then it will be good for our society. Because this will indirectly\
    \ increase trust among each other and building things together. So, this means\
    \ instead of taking help of Alexa or Siri to search Chocolate chip cookie recipe,\
    \ we can ask our family, friends or neighbours."
- desc: The social media isn't providing a variety of communication ways, which cause
    some problems. Nowadays many people's social content are through the internet
    so that according to the idea of city that used to be, there is a lack of the
    ways of communicating in social media. In my opinion, the big company should do
    more like create an environment for more people, different people, and be focus,
    checking those garbage informations, so it can create a better place for every
    people.
- desc: 'As a future programmer I learned that the content/product/service which I''m
    going to showcase to my audience should cover the following points:

    -should be relevant/what they are actually hoping of

    -should be important

    -proper check of their feeling ,will they be comfortable enough in exploring more
    into it

    -making it less challenging and more user friendly in terms of technology and
    public friendly in terms of emotions

    -rather than creating a rigid design of one owner and owner''s rules, making it
    a bit liberal giving people appropriate power over it, so they feel the ownership
    and the warmth.'
- desc: 'In the meeting we did some activities like you asked us to post the first
    link of the website about the recipe of chocolate chip cookie. And then we decided
    which is the most recommended one. We did the same with Covid-19 vaccines. I think
    people got almost same websites because of the highest recommended one by the
    google. It also sometimes depends on the history of our searches.

    I think that''s what we discussed in meeting-5.

    See you in the next meeting.'
- desc: this was a very interesting meeting. As I got flabbergasted by the fact that
    a thing like a filter bubble really exist as we searched about covid 19 and choco-chip
    cookie etc. Now, I find as a threat because it can really affect a person's thinking
    and really can be used to promote some type of propaganda. We are relying too
    much on the internet and usually, people can be misled by the internet pretty
    easily. Alexa as a threat to society seems pretty real to me. However, as long
    it maintains a balance between the data shared and comfort, its a great tool.
- desc: In the last class I enjoyed the exercise when we all searched up the same
    things on google and we could all see first hand how we all get different results
    from the searches we make on google depending on the individual.
- desc: you can say that google search is totally depend on the certain matrics you
    can say depend upon location, area. And the link which is showed on the top of
    the search is depend upon the how amount of trafficing which are used by users
    as well as google algorithm.
- desc: In the past meeting, the concept of filter bubbles had been highlighted very
    well. I like the practical thing, we all did in the last meeting. And Due to some
    algorithm, every device gets different result.
- desc: In the last meeting, we did some searches to verify about filter bubbles theory
    . And that was true in most of cases. So its real thing that these algorithms
    edit our web result accordingly, without even letting us know.
- desc: In this meeting the search result was really different as i saw and that was
    one of the same thhing that was discussed in the video as well that it depends
    on the personalization filter depending on you what you saw and where, so it was
    a bit of a shock that it so precisely monitor your search or activity or in this
    case the clicks which is already to exposed and i think which makes it more dangereous
    is the eco system that we are in and also the knowledge is really less, one of
    the reason i thought was as there is no structural enviornment on platforms like
    facebook or instagram or any newspaper sites makes it really hard to believe the
    points or knowledge reagarding it
- desc: Alexa' is threatening society's. the word threatening is a bit ambiguous because
    as the years go by and technology advances we as humans become too careless and
    less about how things operate . So when you ask your Alexa for the recipe for
    a meal, you are stranded so you only want the recipe fast and only the best recipe.
    Hence the individual doesn't care why it came up but that it came up.
- desc: As we discussed in last class, different people gets different search result
    as per their previous search. For example, if I search particular school here
    in Regina, I will get the first few links of that school information page afterword
    their will be a different school, however, this school will be here in Regina
    only. Now, if my friend who is in Calgary searching a school here in Regina, he
    will get the first couple of link related to that school afterword he will get
    the links of school located in Calgary itself. So, here we saw how the search
    engines like google use our location and display things in that manner. Moreover,
    if I search any sports person on google it will also show "people also search
    for" column. This column will be different for every person as per their pervious
    search. This is good in a way but the companies uses our personal information
    to make it appropriate for us.
- desc: "In the last meeting, we further discussed and experimented on the filter\
    \ bubble concept. We all were asked to search on the same top with the same name\
    \ for instance \"Covid-19\". The results were similar to the ones we saw on the\
    \ videos posted from meeting 5. Everyone got different search results due to their\
    \ filter bubbles. Different results were shown to everyone which were personally\
    \ tailored to their queries and search results. Some of the students were missing\
    \ the important piece of information on the first page of their results. An experiment\
    \ was conducted by Fr\xE9d\xE9ric Bouchard where he asked about the recipe of\
    \ chocolate chip cookies from voice assistance, such as Siri and Alexa. The AI\
    \ in the voice assistance used the algorithms to pull out the recipe, but the\
    \ source of the recipe was unknown and there was no way of knowing that why that\
    \ recipe was given out of hundreds of other recipes on the internet. People, without\
    \ knowing the credibility of the source, will believe in the results given by\
    \ these AI-controlled voice assistance. People nowadays believe in whatever is\
    \ given on the internet without knowing the credibility of the source. Although\
    \ the truth is the internet will only show us the things we want to see, but not\
    \ necessarily what is important."
- desc: 'In meeting 5. I watched the report "How ''Alexa'' is threatening society''s
    trust in scientific expertise". It was talk about in most of people''s mind the
    position of AI is beyond the scientist that invent them. people are over depending
    on internet, Fake news and real news are mixing together. If the percentage of
    trust tend to fake news, then the Fake news will become the true. This is how
    internet violence come from, some small case will become a huge problem such as
    roll a snowball through thousand to ten thousand netizen. And the worst result
    is the person that being in the center of internet violence will suicide. And
    the question I got in meeting 5 is : how to filter the unhealthy internet news,
    information, report to stop it spread by butterfly effect?'
- desc: 'We need to the be more careful about how we approach artificial intelligence
    in future as I said in meeting 4 and the article about ''Alexa'' says that we
    know very little about these AI''s, we don''t question anything as we just assume
    they are correct we don''t check the credibility of the source at all.

    The political part of the article was the thing I did not understand.

    I would like to know how are they improving these AI assistant.

    if you ask google assistant something she just shows the first web search she
    can find.'
- desc: Hearing what others say about how just the moral and obligation systems behind
    a company really opens up more conversations and how big the system really is.
    To think all these things are done by a code, a code that decides what we see
    and what we don't see is beyond amazing ability wise but scary to think about
    looking at it. We may continue to be forced into our own bubble but if you can
    keep your eyes open all these developments will be spectacular to see just don't
    let it consume you. I would like to learn the future possibilities of growth in
    these things, maybe even a fully functional fact-checker that never gets it wrong,
    this may lead to media not being able to lie and we would always be able to see
    the truth and no falsification of any sort.
- desc: 'Based on the in-class activities, it proves that online filter bubbles abound
    on the Internet. However, depend on what information we are searching for, some
    results from search engine can be roughly divided into several categories instead
    of everyone getting a completely different result. For the special keywords, the
    results were nearly the same for different users. The conclusion of in-class activities
    is quite different from my understanding of online filter bubbles. But, there
    is no denying that online filter bubbles do have impact on the information retrieved
    by users.

    After reading "How ''Alexa'' is threatening society''s trust in scientific expertise",
    I am deeply touched. It is absolutely true that people have an unprecedented dependence
    on artificial intelligence and search engine with the rapid development of information
    technology. Unfortunately, most people have preconceived problems in terms of
    information processing. In today''s highly informationized society, this problem
    has been expanded infinitely such that people always unconditionally believe the
    information they get first without their own analysis. How to find a balance between
    independent thinking and passive acceptance is a problem worth thinking about
    for each of us.'
- desc: I would like to know more about how 'Alexa' is threatening society's trust
    in scientific expertise
- desc: The working of filter bubble and the outcome of it in our results platform
    can be understood by the experiment conducted by the professor of university of
    montreal. It is surprising as to how individuals get different results for the
    same search done on different devices. It shows the way algorithms works in governing
    the results shown to us. Due to this filters, some of the important results are
    missed by the user which they must know and its all because of the algorithms.
- desc: The idea of the filter bubbles does not work very well when we searched for
    different topics since most people get the same response from google search. However,
    when we googled the covid vaccine it did not give the government site or WHO site.
    It raises the concern of the possibility of putting inaccurate information on
    the top page. A few years ago someone in China searched his illness issues on
    the internet using Baidu(Chinese search engine) she got traped to believe a hospital
    to be as good as some major hospitals. Which gives them false information. So
    I think the search engine should be responsible for afor their search result in
    some way, especially when the result can do harm.
- desc: In this lesson we discuss and practice the results of a computer search.Obviously,
    most people are able to find the corresponding URL very quickly.One of the important
    points of the article in this class is that computers do not eliminate trust between
    people, or between people and scientists.The paper argues that the original traditional
    trust relationship is broken because of the shortcomings of human nature and the
    differences between human and machine in search.It is not difficult to understand,
    after all, the existing computer network is based on big data and engine work,
    this model is naturally faster than the traditional model.For example, compared
    with "We Media" platforms, traditional TV stations may be more convincing in the
    propaganda of science, but their communication efficiency is not as good as that
    of "We Media" platforms.But my personal opinion is that computer networks know
    the way of information, not the source of information, and the source of information
    is still generated by people.More distrust is simply due to the lack of more reliable
    communication between people.So I think there is a fundamental need to enhance
    the reliability of the information.And more transparent disclosure of information
    analysis methods, this is the way to improve the computer Internet information
    trust.
- desc: In this I learned that how Alexa or Siri threatened the society trust about
    scientific expertise. Most of the people nowadays using Alexa or Siri for search
    on web rather than searching Manually. the searches made by Alexa are depends
    upon where you are sitting and what type of mobile or pc you are using. And it
    feeding the distrust in humans as if we searching about something it show the
    different sites as we have taken example of covid19 in our class and it was different
    results to everyone. They shows the result but we cant say its right or wrong
    but we are just believing it because our understanding is just getting limited
    to the artificial intelligence.
- desc: "It was really surprising how everyone's search result was different than\
    \ others and I as a CS student I just figure that out. But in the same time it's\
    \ kind of alarming because it shows how everyone is being isolated and these computer\
    \ algorithms are making another small world for everyone where they only see what\
    \ these algorithms think are good for them not something that is important to\
    \ the world. This censorship is the same as the last meeting like how we talked\
    \ about companies censor things based on things that we might be more interested\
    \ in, rather than the import things that are going on around the world. Like how\
    \ we discussed facebook's newsfeed uses algorithms as a gate keepers to censor\
    \ things that we might be interested on based on relevant not what's important.\
    \ They try to make us comfortable so we keep use their product and they collect\
    \ more data resulting in more profit for them. On the other hand like how Dr.\
    \ Bouchard said people are losing their trust in scientist because it's being\
    \ turned into a political camp by the politician rather than people with knowledge\
    \ in their field. Like how we see with COVID pandemic the authorities tries to\
    \ put to all the negative side on the doctors and scientists like when they introduce\
    \ restriction and bans to make it look like it's not them but theses scientists\
    \ who made the decision and made their life harder.\_"
- desc: "In the last class we came to learn about the algorithms of the search engines\
    \ and how every time we get different search results. In an experiment we tried\
    \ searching different topics which are Governor of Canada, the recipe of the Chocolate\
    \ chip cookies and COVID-19 vaccine. And we do not know how this system even works.\n\
    Watching the video of \u201CHow \u2018Alexa\u2019 is threatening society\u2019\
    s trust in scientific expertise \u201D I\u2019ve came to learn that we guys need\
    \ to trust the manpower over the internet and the search engines. Which is that\
    \ we if we need the recipe of the chocolate cookies we would not search on the\
    \ Google or any other Search engine we need to ask our mother or our grandmother\
    \ for the freshly baked cookies. Or bake with them and fill our tummies with the\
    \ cookies and milk."
- desc: 'the most important thing you learned from this past meeting

    -> How filter bubble works and how can we make online platforms more public friendly
    than user friendly


    the concept from this past meeting that was the most difficult for you to understand

    -> It was very interesting lecture and nothing felt difficult to me in this lecture.


    what you would like to know more about

    -> How the filter algorithm works and how can we overcome this bubble


    something you encountered that is related to the past meeting

    -> It is when Dr. Hepting gave us activity and how different the result were for
    the same google search that was pretty amazing to know.'
- desc: "I found the topic of meeting very interesting \u201Cfilter bubble\u201D and\
    \ the experiment we did was exciting. I really want to get more information related\
    \ to this topic."
- desc: From Eli Pariser's TED talk I learned about how social media and search engine
    algorithms cause users to only get information that the algorithm thinks they
    want to see. This leads to echo chambers where people only receive the same information
    and perspectives over and over again, which can lead to very closed-minded thinking.
    I have noticed this personally on apps like twitter where I only really see tweets
    from people with similar viewpoints to me over and over again.
- desc: "\u201CHow \u2018Alexa\u2019 is threatening society\u2019s trust in scientific\
    \ expertise\u201D: Since the technology is developing day by day, there are many\
    \ explosive inventions related to computer and digital system such as AI (Artificial\
    \ Intelligence). In my opinion, the most prominent in those inventions is the\
    \ virtual assistant which is developed by many companies such as Apple (Siri)\
    \ and Amazon (Alexa). Siri or Alexa could help people a lot whenever they need\
    \ them. Users could active them by using their voice. For that reason, Siri and\
    \ Alexa are also known as \u201Cvoice assistance\u201D. From my perspective, voice\
    \ assistance helps people a lot in daily life. It could help people save time\
    \ for searching something on the Internet. It definitely always provides reliable\
    \ information for users. However, there are still some people do not refuse not\
    \ to use them because they are not believing in them. They do not have a trust\
    \ on science/computer and also people who create them. Hopefully, in the near\
    \ future, more people will accept those AI products so that it could have a chance\
    \ to help them in life. It could also help to build a modern world than ever."
- desc: 'As we searched about the covid 19 vaccine, and put the link in the class
    activity. As I observed that every link was different because of their interests
    or we can say filter bubbles.

    Also we searched for the recipe to make cookies, and in the experiment, when it
    was asked from AI devices such as alexa, I also tried it on my alexa, the same
    way Bouchard did. Even though i was able to find many other recipes over the internet.
    As filter bubbles, shows us those links which people has searched more for.

    It filters the links according to the searches of the people who viewed the over
    the internet. Well it is actually automatically filtered, no matter if it is wrong
    or right, most people are likely to believe what is on the internet. Sometimes,
    it can be wrong for the user.'
- desc: The question, Eli says, is that while the Internet reveals what we want to
    see, we don't really need to see what we need to see. The filter bubble is what
    he calls it. It's a bubble of exclusive knowledge of your own, so you can't see
    what isn't going into it. It was seen as a liberation from the power of people
    who owned and edited the content you saw when the Internet was created. As an
    example, as discussed on your website, talking about Alexa or Siri or any other
    responsive AI, they listen to us all the time and show us ads on our device related
    to what we have been talking about. Other than the providing of knowledge through
    social media on some level the social media platforms don't have any modern-day
    obligations. They are more of a source for communication or entertainment.
- desc: In this meeting I learned about filter bubble that how it filters your search
    results according to individuals search. I learnt that how different people get
    different search results on the basis of location and according to the popularity
    of the URL.
- desc: People trust computers more than human scientists because they think computers
    are more reliable, and there is still a gap between people. If people want to
    deal with this problem, the certification of scientists online is essential. Only
    the authority of scientists has been certified, and I believe the public will
    believe in such scientists. For individuals, because human beings are social creatures,
    it is necessary to communicate with others. But only online social networking
    is not enough; we should communicate more with friends face to face.
- desc: In this class, we learned about how social media publishes false news. In
    my opinion, the companies have tried to fix this by adding the fact check feature
    which is very interesting and can help limit the expansion of fake news.
- desc: 'Hi all,


    The biggest and most interesting takeaway for me from the meeting was the importance
    of SEO (Search Engine Optimization) for any website, public or private. I was
    surprised to see raps.org come up as first when searched for "COVID 19 Vaccine".
    My point being, government data could''ve been optimized more so that data comes
    up first when searched for.'
- desc: Well what i learn from this is on how the aligithem can change what we view
    or what we think we want so we can get filter results that we might not want to
    have
- desc: 'the most important thing you learned from this past meeting

    -it is that there are different search results for different persons though we
    search for the same thing at same time. This is the bubble filter that shows us
    different results.

    the concept from this past meeting that was the most difficult for you to understand

    bubble sort

    what you would like to know more about

    i would like to know more about the how social media is interlinked with the bubble
    sort and how is it a greater platform

    something you encountered that is related to the past meeting

    filter bubble'
