---
title: CS-280 (201910) Mtg 37
breadcrumb: 37 (10-Apr-19)
mtg_nbr: 37
total_meet: 37
mtg_date: 10-Apr-19
layout: bg-image
---
{% include mtg-pagination.html %}
<h1 class="text-center">{{ page.mtg_date }}</h1>
<hr />

* [Google finds AI raises ethical questions we struggle to answer](https://www.ft.com/content/0e563d1c-59f8-11e9-840c-530737425559)
  * "When an organisation establishes an ethics committee, the decision acknowledges that existing people and processes do not meet critical challenges. But there is a paradox here: how to design a fix for a problem you know you don’t yet fully understand."
  * "As the mathematician Cathy O’Neil is fond of saying, algorithms are just opinions expressed in numbers. But the question of whose opinions they are, supporting which norms, remains contentious."
* [Exclusive: Google cancels AI ethics board in response to outcry](https://www.vox.com/future-perfect/2019/4/4/18295933/google-cancels-ai-ethics-board)
  * [Googlers Against Transphobia and Hate](https://medium.com/@against.transphobia/googlers-against-transphobia-and-hate-b1b0a5dbf76?fbclid=IwAR0Nd6ObNE8kEMlo0yrQ96vNyhD9Hq_wujRltse6qh-HW_FmBKPfXnXy9mU)
  * [The American public is already worried about AI catastrophe](https://www.vox.com/future-perfect/2019/1/9/18174081/fhi-govai-ai-safety-american-public-worried-ai-catastrophe)
* [AI systems should be accountable, explainable, and unbiased, says EU](https://www.theverge.com/2019/4/8/18300149/eu-artificial-intelligence-ai-ethical-guidelines-recommendations):
1. Human agency and oversight — AI should not trample on human autonomy. People should not be manipulated or coerced by AI systems, and humans should be able to intervene or oversee every decision that the software makes.
1. Technical robustness and safety — AI should be secure and accurate. It shouldn’t be easily compromised by external attacks (such as adversarial examples), and it should be reasonably reliable.
1. Privacy and data governance — Personal data collected by AI systems should be secure and private. It shouldn’t be accessible to just anyone, and it shouldn’t be easily stolen.
1. Transparency — Data and algorithms used to create an AI system should be accessible, and the decisions made by the software should be “understood and traced by human beings.” In other words, operators should be able to explain the decisions their AI systems make.
1. Diversity, non-discrimination, and fairness — Services provided by AI should be available to all, regardless of age, gender, race, or other characteristics. Similarly, systems should not be biased along these lines.
1. Environmental and societal well-being — AI systems should be sustainable (i.e., they should be ecologically responsible) and “enhance positive social change”
1. Accountability — AI systems should be auditable and covered by existing protections for corporate whistleblowers. Negative impacts of systems should be acknowledged and reported in advance.

[Google's AI Principles](https://ai.google/principles/), Objectives for AI Applications:

1. Be socially beneficial.
1. Avoid creating or reinforcing unfair bias.
1. Be built and tested for safety.
1. Be accountable to people.
1. Incorporate privacy design principles.
1. Uphold high standards of scientific excellence.
1. Be made available for uses that accord with these principles.

<https://en.wikipedia.org/wiki/Volkswagen_emissions_scandal>

### End of Meetings
* Exam will cover the whole semester, with more emphasis on work since midterm. Question topics will come from meetings exclusively, from what is listed on web pages for meetings (including media from meetings and links)
* Some more marks have been uploaded, remainder will be done before final exam
* [Rate Your Groupwork Group](https://urcourses.uregina.ca/mod/assign/view.php?id=925585)
* Exam question suggestions or comments? [201910 Midterm]({{ "/assets/teaching/pdf/CS-280-201910_exam-1-midterm.pdf" | relative_url }}), [201710 Final]({{ "/assets/teaching/pdf/CS-280-201710_exam-2-final.pdf" | relative_url }})

* [Inspirations]({{ "/research/inspirations.html" | relative_url }})

{% include meeting-media.html mtg_media=off_med mtg=page.mtg_nbr %}
